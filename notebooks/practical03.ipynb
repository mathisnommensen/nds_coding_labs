{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Neural Data Science_\n",
    "\n",
    "Lecturer: Dr. Jan Lause, Prof. Dr. Philipp Berens\n",
    "\n",
    "Tutors: Jonas Beck, Fabio Seel, Julius Würzler\n",
    "\n",
    "Summer term 2025\n",
    "\n",
    "Student names: Nina Lutz, Mathis Nommensen\n",
    "\n",
    "LLM Disclaimer: <span style='background: yellow'>*Did you use an LLM to solve this exercise? If yes, which one and where did you use it? [Copilot, Claude, ChatGPT, etc.]* </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Single-cell data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install memory-profiler #N: i needed to install this. delete code block if not needed anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook #N: had to change this\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import string\n",
    "\n",
    "import scipy as sp\n",
    "from scipy import sparse\n",
    "import sklearn\n",
    "\n",
    "## add your packages ##\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "import memory_profiler\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import umap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%load_ext memory_profiler\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import black\n",
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load(line_length=79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_path = Path(\"../results/variables\")\n",
    "figures_path = Path(\"../results/figures\")\n",
    "data_path = Path(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.style.use(\"matplotlib_style.txt\")\n",
    "plt.style.use(\"../matplotlib_style.txt\")  # N: had to change this as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project and data description\n",
    "\n",
    "In this project, we are going to work with the typical methods and pipelines used in single-cell data analysis and get some hands-on experience with the techniques used in the field. For that, we will be using Patch-seq multimodal data from cortical neurons in mice, from Scala et al. 2021 (https://www.nature.com/articles/s41586-020-2907-3#Sec7). From the different data modalities they used, we will focus on transcriptomics and electrophysiological data. \n",
    "\n",
    "In a real-world scenario, single cell data rarely comes with any \"ground truth\" labels. Often, the goal of researchers after measuring cells is to precisely classify them, grouping them into families or assigning them cell types based on the recorded features. This is normally done using usupervised methods, such as clustering methods.\n",
    "\n",
    "However, the single-cell data that we are using in this project has some cell types assigned to each cell. These are not \"ground truth\" type annotations, but were one of the results from the original Scala et al. work. Still, we are going to use those annotations for validation (despite them not really being ground truth) to sanity-check some of our analyses, such as visualizations, clustering, etc. We will mainly work with cell types (`rna_types`, 77 unique types) and cell families (`rna_families`, 9 unique families).\n",
    "\n",
    "From the transcriptomics mRNA counts, we will only work with the exon counts for simplicity. Some of the electrophysiological features are not high-quality recordings, therefore we will also filter them out."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# META DATA\n",
    "\n",
    "meta = pd.read_csv(data_path / \"m1_patchseq_meta_data.csv\", sep=\"\\t\")\n",
    "\n",
    "cells = meta[\"Cell\"].values\n",
    "\n",
    "layers = meta[\"Targeted layer\"].values.astype(\"str\")\n",
    "cre = meta[\"Cre\"].values\n",
    "yields = meta[\"Yield (pg/µl)\"].values\n",
    "yields[yields == \"?\"] = np.nan\n",
    "yields = yields.astype(\"float\")\n",
    "depth = meta[\"Soma depth (µm)\"].values\n",
    "depth[depth == \"Slice Lost\"] = np.nan\n",
    "depth = depth.astype(float)\n",
    "thickness = meta[\"Cortical thickness (µm)\"].values\n",
    "thickness[thickness == 0] = np.nan\n",
    "thickness = thickness.astype(float)\n",
    "traced = meta[\"Traced\"].values == \"y\"\n",
    "exclude = meta[\"Exclusion reasons\"].values.astype(str)\n",
    "exclude[exclude == \"nan\"] = \"\"\n",
    "\n",
    "mice_names = meta[\"Mouse\"].values\n",
    "mice_ages = meta[\"Mouse age\"].values\n",
    "mice_cres = np.array(\n",
    "    [\n",
    "        c if c[-1] != \"+\" and c[-1] != \"-\" else c[:-1]\n",
    "        for c in meta[\"Cre\"].values\n",
    "    ]\n",
    ")\n",
    "mice_ages = dict(zip(mice_names, mice_ages))\n",
    "mice_cres = dict(zip(mice_names, mice_cres))\n",
    "\n",
    "print(\"Number of cells with measured depth:    \", np.sum(~np.isnan(depth)))\n",
    "print(\"Number of cells with measured thickness:\", np.sum(~np.isnan(thickness)))\n",
    "print(\"Number of reconstructed cells:          \", np.sum(traced))\n",
    "\n",
    "sliceids = meta[\"Slice\"].values\n",
    "a, b = np.unique(sliceids, return_counts=True)\n",
    "assert np.all(b <= 2)\n",
    "print(\"Number of slices with two cells:        \", np.sum(b == 2))\n",
    "\n",
    "# Some consistency checks\n",
    "assert np.all(\n",
    "    [\n",
    "        np.unique(meta[\"Date\"].values[mice_names == m]).size == 1\n",
    "        for m in mice_names\n",
    "    ]\n",
    ")\n",
    "assert np.all(\n",
    "    [\n",
    "        np.unique(meta[\"Mouse age\"].values[mice_names == m]).size == 1\n",
    "        for m in mice_names\n",
    "    ]\n",
    ")\n",
    "assert np.all(\n",
    "    [\n",
    "        np.unique(meta[\"Mouse gender\"].values[mice_names == m]).size == 1\n",
    "        for m in mice_names\n",
    "    ]\n",
    ")\n",
    "assert np.all(\n",
    "    [\n",
    "        np.unique(meta[\"Mouse genotype\"].values[mice_names == m]).size == 1\n",
    "        for m in mice_names\n",
    "    ]\n",
    ")\n",
    "assert np.all(\n",
    "    [\n",
    "        np.unique(meta[\"Mouse\"].values[sliceids == s]).size == 1\n",
    "        for s in sliceids\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Ground truth labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out low quality cells in term of RNA\n",
    "print(\n",
    "    \"There are\",\n",
    "    np.sum(meta[\"RNA family\"] == \"low quality\"),\n",
    "    \"cells with low quality RNA recordings.\",\n",
    ")\n",
    "exclude_low_quality = meta[\"RNA family\"] != \"low quality\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rna_family = meta[\"RNA family\"][exclude_low_quality]\n",
    "rna_type = meta[\"RNA type\"][exclude_low_quality]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(np.unique(rna_family)))\n",
    "print(len(np.unique(rna_type)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(data_path / \"dict_rna_type_colors.pkl\", \"rb\")\n",
    "dict_rna_type_colors = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rna_type_colors = np.vectorize(dict_rna_type_colors.get)(rna_type)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcriptomic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ COUNTS\n",
    "data_exons = pd.read_csv(\n",
    "    data_path / \"m1_patchseq_exon_counts.csv.gz\", na_filter=False, index_col=0\n",
    ")\n",
    "\n",
    "assert all(cells == data_exons.columns)\n",
    "genes = np.array(data_exons.index)\n",
    "\n",
    "# filter out low quality cells in term of rna family\n",
    "exonCounts = data_exons.values.transpose()[exclude_low_quality]\n",
    "print(\"Count matrix shape (exon):  \", exonCounts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENE LENGTH\n",
    "\n",
    "data = pd.read_csv(data_path / \"gene_lengths.txt\")\n",
    "assert all(data[\"GeneID\"] == genes)\n",
    "exonLengths = data[\"exon_bp\"].values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Electrophysiological features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPHYS DATA\n",
    "\n",
    "ephysData = pd.read_csv(data_path / \"m1_patchseq_ephys_features.csv\")\n",
    "ephysNames = np.array(ephysData.columns[1:]).astype(str)\n",
    "ephysCells = ephysData[\"cell id\"].values\n",
    "ephysData = ephysData.values[:, 1:].astype(\"float\")\n",
    "names2ephys = dict(zip(ephysCells, ephysData))\n",
    "ephysData = np.array(\n",
    "    [\n",
    "        names2ephys[c] if c in names2ephys else ephysData[0] * np.nan\n",
    "        for c in cells\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Number of cells with ephys data:\", np.sum(np.isin(cells, ephysCells)))\n",
    "\n",
    "assert np.sum(~np.isin(ephysCells, cells)) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering ephys data\n",
    "\n",
    "features_exclude = [\n",
    "    \"Afterdepolarization (mV)\",\n",
    "    \"AP Fano factor\",\n",
    "    \"ISI Fano factor\",\n",
    "    \"Latency @ +20pA current (ms)\",\n",
    "    \"Wildness\",\n",
    "    \"Spike frequency adaptation\",\n",
    "    \"Sag area (mV*s)\",\n",
    "    \"Sag time (s)\",\n",
    "    \"Burstiness\",\n",
    "    \"AP amplitude average adaptation index\",\n",
    "    \"ISI average adaptation index\",\n",
    "    \"Rebound number of APs\",\n",
    "]\n",
    "features_log = [\n",
    "    \"AP coefficient of variation\",\n",
    "    \"ISI coefficient of variation\",\n",
    "    \"ISI adaptation index\",\n",
    "    \"Latency (ms)\",\n",
    "]\n",
    "\n",
    "X = ephysData[exclude_low_quality]\n",
    "print(X.shape)\n",
    "for e in features_log:\n",
    "    X[:, ephysNames == e] = np.log(X[:, ephysNames == e])\n",
    "X = X[:, ~np.isin(ephysNames, features_exclude)]\n",
    "\n",
    "keepcells = ~np.isnan(np.sum(X, axis=1))\n",
    "X = X[keepcells, :]\n",
    "print(X.shape)\n",
    "\n",
    "X = X - X.mean(axis=0)\n",
    "ephysData_filtered = X / X.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete later\n",
    "print(ephysNames.shape)\n",
    "print(ephysData.shape)\n",
    "print(ephysData_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.isnan(ephysData_filtered))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research questions to investigate\n",
    "\n",
    "**1) Inspect the data by computing key statistics.** For RNA counts, you can compute and plot statistics, e.g. total counts per cell, number of expressed genes per cell, mean count per gene, variance per gene, mean-variance relationship... See https://www.embopress.org/doi/full/10.15252/msb.20188746 for common quality control statistics. Keep in mind that the RNA data in this project is read counts, not UMI counts, so it is not supposed to follow a Poisson distribution.> To get an idea of the technical noise in the data, you can plot count distributions of single genes within cell types (like in the lecture). \n",
    "\n",
    "Similarly, you can compute and plot statistics over the electrophyiological data. Also, investigate the distribution of \"ground truth\" labels. Comment about other relevant metadata, and think if you can use it as some external validation for other analyses. If you do use other metadata throughout the project, explain why and what you get out of it. Take into account that certain features may not be very informative for our purposes (e.g. mouse age), so only choose features that provide you with useful information in this context. If you want to get additional information about the metadata, have a look at the extended data section in the original publication (e.g., cre-lines in Figure 1c in the extended data).\n",
    "\n",
    "**2) Normalize & transform the data; select genes & apply PCA.** There are several ways of normalizing the RNA count data (Raw, CPM, CPMedian, RPKM, see https://www.reneshbedre.com/blog/expression_units.html, https://translational-medicine.biomedcentral.com/articles/10.1186/s12967-021-02936-w). Take into account that there are certain normalizations that only make sense for UMI data, but not for this read count data. You also explored different transformations in the assignment (none, log, sqrt). Compare how the different transformations change the two-dimensional visualization. After normalization and transformation, choose a set of highly variable genes (as demonstrated in the lecture) and apply PCA. Play with the number of selected genes and the number of PCA components, and again compare their effects on the two-dimensional visualization.\n",
    "\n",
    "**3) Two-dimensional visualization.** To visualize the RNA count data after normalization, transformation, gene selection and PCA, try different methods (just PCA, t-SNE, UMAP, ..) and vary their parameters (exaggeration, perplexity, ..). Compare them using quantitative metrics (e.g., kNN accuracy in high-dim vs. two-dim, kNN recall). Please refer to Lause et al., 2024 (https://doi.org/10.1371/journal.pcbi.1012403) where many of these metrics are discussed and explained to make an informed choice on which metrics to use. Think about also using the electrophysiological features and other metadata to enhance different visualizations.\n",
    "\n",
    "**4) Clustering.** To find cell types in the RNA count data, you will need to look for clusters. Try different clustering methods (leiden, GMM). Implement a negative binomial mixture model. For that you can follow a similar method that what is described in Harris et al. 2018 (https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.2006387#abstract0), with fixed r (r=2). Feel free to simplify the setup from the paper and not optimize over the set of important genes S but fix it instead, or skip the split and merge part of their clustering algorithm. A vanilla NBMM implementation should suffice. Take into account that the NBMM tries to cluster data that follows a negative binomial distribution. Therefore, it does not make sense to apply this clustering method to all kinds of normalized and transformed data. Please refer to the Harris et al. 2018 publication for the appropriate choice of normalization, and reflect on why this normalization makes sense. Evaluate your clustering results (metrics, compare number of clusters to original labels,...).\n",
    "\n",
    "**5) Correlation between electrophysiological features and genes/PCs.** Finally, connect RNA counts and functional data: Most likely, there will be interesting relationships between the transcriptomic and electrophyiological features in this data. Find these correlations and a way of visualizing them. In studying correlations using the PCA-reduced version of the transcriptomics data, it could be interesting to study PC loadings to see which genes are dominating which PCs. For other advanced analyses, you can get inspitation from Kobak et al., 2021 (https://doi.org/10.1111/rssc.12494).\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "\n",
    "## 1.1 QC Statistics per cell\n",
    "\n",
    "RNA Counts and stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exonCounts.shape[0]\n",
    "exonCounts.shape[1]\n",
    "exonCounts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total counts per cell (count depth)\n",
    "\n",
    "# exonCounts  # shape = 1232 cells x 42466 genes\n",
    "total_counts_per_cell = exonCounts.sum(axis=1)\n",
    "\n",
    "# plot\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "axes[0].hist(\n",
    "    total_counts_per_cell, bins=50, color=\"skyblue\", edgecolor=\"black\"\n",
    ")\n",
    "axes[0].set_xlabel(\"Total RNA counts per cell\")\n",
    "axes[0].set_ylabel(\"Number of cells\")\n",
    "axes[0].set_title(\"Distribution of Total Counts Per Cell\")\n",
    "\n",
    "axes[1].bar(\n",
    "    range(len(total_counts_per_cell)),\n",
    "    total_counts_per_cell,\n",
    "    width=1,\n",
    "    alpha=0.5,\n",
    "    color=\"blue\",\n",
    ")\n",
    "axes[1].set_yscale(\"log\")\n",
    "axes[1].set_xlabel(\"Cell index\")\n",
    "axes[1].set_ylabel(\"Total RNA counts\")\n",
    "axes[1].set_title(\"Total Counts Per Cell\")\n",
    "\n",
    "# Rank-ordered plot of total counts per cell - Figure 2C in the paper\n",
    "sorted_counts = np.sort(total_counts_per_cell)[::-1]\n",
    "\n",
    "axes[2].plot(sorted_counts)\n",
    "axes[2].set_yscale(\"log\")\n",
    "axes[2].set_xlabel(\"Ranked Cell Index\")\n",
    "axes[2].set_ylabel(\"Total Counts (log scale)\")\n",
    "axes[2].set_title(\"Rank-ordered Total Counts per Cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Interpretation:*\n",
    "\n",
    "Left:\n",
    "* The histogram reveals a right-skewed distribution of total RNA counts per cell, with most cells clustered between 0 and 5 million counts.\n",
    "\n",
    "Middle:\n",
    "* shows that most cells have a comparable number of total counts, with a few outliers having significantly higher and lower counts (e.g. cells around index 400 and 500).\n",
    "\n",
    "Right:\n",
    "* The rank-ordered curve shows a gradual decay in RNA counts, with a steep drop-off in low-quality cells at the tail—typical of single-cell data \n",
    "* most cells have comparable total cells\n",
    "* the first ~20 cells have a lot more counts than the rest\n",
    "* the last ~100 cells have very few counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of expressed genes per cell\n",
    "expressed_genes_per_cell = (exonCounts > 0).sum(axis=1)\n",
    "\n",
    "# plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "axes[0].scatter(range(len(expressed_genes_per_cell)), expressed_genes_per_cell)\n",
    "axes[0].set_xlabel(\"Cell Index\")\n",
    "axes[0].set_ylabel(\"Expressed Genes\")\n",
    "axes[0].set_title(\"Total Number of Expressed Genes per Cell\")\n",
    "\n",
    "axes[1].hist(expressed_genes_per_cell, bins=50)\n",
    "axes[1].set_xlabel(\"Total number of expressed genes per cell\")\n",
    "axes[1].set_ylabel(\"Number of cells\")\n",
    "axes[1].set_title(\"Distribution of Expressed Genes Per Cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Interpretation:*\n",
    "\n",
    "Left: Total number of expressed genes per cell\n",
    "* The scatter plot shows considerable variation in the number of genes detected per cell, with a spread ranging from around 2,000 to over 17,000 genes, whereas most cells have between 5000 and 11,000 genes expressed.\n",
    "\n",
    "Right: Distribution of expressed genes per cell\n",
    "* Shows a similar pattern as the left plot, with most cells having between 2000 and 11,000 genes expressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fraction of mitochondrial genes\n",
    "\n",
    "# mt_like_genes = [g for g in genes if \"mt\" in g.lower()]\n",
    "# print(mt_like_genes)\n",
    "# after checking the gene names, we can assume that mitochondrial genes start with \"mt-\" or \"MT-\"\n",
    "mt_gene_mask = np.char.startswith(genes.astype(str).astype(\"U\"), \"mt-\")\n",
    "\n",
    "print(\"Number of mitochondrial genes found:\", np.sum(mt_gene_mask))\n",
    "\n",
    "# Sum counts over mitochondrial genes per cell\n",
    "mt_counts_per_cell = exonCounts[:, mt_gene_mask].sum(axis=1)\n",
    "\n",
    "# Fraction mitochondrial\n",
    "fraction_mito = mt_counts_per_cell / total_counts_per_cell\n",
    "\n",
    "# Print statistics\n",
    "print(\"Mean mitochondrial fraction:\", np.mean(fraction_mito))\n",
    "print(\"Cells with >20% mitochondrial:\", np.sum(fraction_mito > 0.2))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.hist(fraction_mito, bins=50, color=\"salmon\", edgecolor=\"black\")\n",
    "plt.xlabel(\"Fraction of Mitochondrial Counts per Cell\")\n",
    "plt.ylabel(\"Number of Cells\")\n",
    "plt.title(\"Distribution of Mitochondrial RNA Content\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Interpretation:*\n",
    "\n",
    "* most cells have a low fraction of mitochondrial genes (~1.7%), with a few outliers having a higher fraction (e.g. cells around index 400 and 500)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"could be deleted later\"\"\"\n",
    "\n",
    "# Look for any gene names containing 'mt' or 'MT'\n",
    "mt_like_genes = [g for g in genes if \"mt\" in g.lower()]\n",
    "print(mt_like_genes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 QC Statistics per gene\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean expression across all cells\n",
    "mean_expression_across_cells = exonCounts.mean(axis=0)\n",
    "print(\"Mean expression across all cells:\", mean_expression_across_cells.shape)\n",
    "# variance across all cells\n",
    "variance_expression_across_cells = exonCounts.var(axis=0)\n",
    "print(\"Variance across all cells:\", variance_expression_across_cells.shape)\n",
    "\n",
    "# plot looks sparse, so log transform the data\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.scatter(\n",
    "    mean_expression_across_cells + 1e-3,  # avoid log(0)\n",
    "    variance_expression_across_cells + 1e-3,\n",
    "    s=5,\n",
    "    alpha=0.5,\n",
    ")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xlabel(\"Mean Expression Across Cells (log scale)\")\n",
    "ax.set_ylabel(\"Variance Across Cells (log scale)\")\n",
    "ax.set_title(\"Mean vs Variance of Gene Expression (log scale)\")\n",
    "x_vals = np.linspace(\n",
    "    min(mean_expression_across_cells + 1e-3),\n",
    "    max(mean_expression_across_cells),\n",
    "    100,\n",
    ")\n",
    "ax.plot(x_vals, x_vals, color=\"red\", linestyle=\"--\", label=\"y = x\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Interpretation:*\n",
    "\n",
    "* The log-log plot reveals a clear mean-variance relationship, where genes with higher mean expression across cells also tend to have higher variance\n",
    "* Almost all genes lie above the y=x line (variance = mean), indicating that the variance is generally higher than the mean for most genes (overdispersion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropout rate / fraction of cells where a gene has zero counts\n",
    "\n",
    "dropout_rate_per_gene = (exonCounts == 0).sum(axis=0) / exonCounts.shape[0]\n",
    "\n",
    "# Quick summary\n",
    "print(\"Mean dropout rate across all genes:\", np.mean(dropout_rate_per_gene))\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot Histogram of dropout rates\n",
    "axes[0].hist(dropout_rate_per_gene, bins=50, color=\"green\", edgecolor=\"black\")\n",
    "axes[0].set_xlabel(\"Dropout Rate (Fraction of Cells with Zero Counts)\")\n",
    "axes[0].set_ylabel(\"Number of Genes\")\n",
    "axes[0].set_title(\"Dropout Rate per Gene\")\n",
    "\n",
    "# Scatter plot of dropout rate vs mean expression\n",
    "axes[1].scatter(\n",
    "    mean_expression_across_cells + 1e-3,  # avoid log(0)\n",
    "    dropout_rate_per_gene,\n",
    "    s=5,\n",
    "    alpha=0.5,\n",
    ")\n",
    "axes[1].set_xscale(\"log\")\n",
    "axes[1].set_ylim(0, 1.05)\n",
    "axes[1].set_xlabel(\"Mean Expression (log scale)\")\n",
    "axes[1].set_ylabel(\"Dropout Rate\")\n",
    "axes[1].set_title(\"Dropout Rate vs. Mean Expression\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Interpretation:*\n",
    "\n",
    "Left:\n",
    "* the majority of genes have a very high dropout rate (mean ~83%), with a large number expressed in fewer than 15-20% of cells and a peak near 100% dropout, i.e. many genes are completely unexpressed in most cells\n",
    "\n",
    "Right:\n",
    "* Strong inverse relationship: Highly expressed genes are detected in nearly all cells (low dropout), while lowly expressed genes are often undetected (high dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "count distributions of single genes within cell types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify cell types\n",
    "unique_cell_types = np.unique(rna_type)\n",
    "\n",
    "# pick genes:\n",
    "# Sst: somatostatin, an inhibitory neuron marker\n",
    "# Slc17a7: an excitatory neuron marker (VGLUT1)\n",
    "# Snap25: a pan-neuronal gene\n",
    "genes_to_plot = [\"Sst\", \"Slc17a7\", \"Snap25\"]\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(10, 8))\n",
    "\n",
    "for ax, gene_name in zip(axes, genes_to_plot):\n",
    "    gene_indices = np.where(genes == gene_name)[0]\n",
    "    gene_index = gene_indices[0]\n",
    "\n",
    "    # get gene counts\n",
    "    gene_counts = exonCounts[:, gene_index]\n",
    "\n",
    "    # group counts by cell type\n",
    "    data = []\n",
    "    for ct in unique_cell_types:\n",
    "        mask = np.array(rna_type) == ct\n",
    "        counts_in_group = gene_counts[mask]\n",
    "        data.append(counts_in_group)\n",
    "\n",
    "    ax.boxplot(\n",
    "        data, tick_labels=unique_cell_types, showfliers=False\n",
    "    )  # the showfliers=False option removes extreme outliers\n",
    "    ax.set_title(f\"Expression of {gene_name}\")\n",
    "\n",
    "    ###M: added logscale to y-axis\n",
    "    ax.set_yscale(\"log\")  # log scale for better visibility\n",
    "\n",
    "    ax.set_ylabel(\"Counts\")\n",
    "    ax.set_xlabel(\"Cell Type\")\n",
    "    ax.tick_params(axis=\"x\", rotation=90, labelsize=8)\n",
    "\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Interpretation:*\n",
    "\n",
    "Sst:\n",
    "* Expression is highly enriched in specific inhibitoy cell types (notably those starting with \"Sst\"), occasionally enriched expression in other celltypes, but no broader pattern visible.\n",
    "\n",
    "Slc17a7:\n",
    "* Expression is enriched in many cells, but most obviously in cell types from L2 to L6, which belong to a family of excitatory neurons. This suggests that Slc17a7 is a marker for excitatory neurons in the cortex, as it is known to be expressed in glutamatergic neurons.\n",
    "\n",
    "Snap25:\n",
    "* This gene shows widespread expression across nearly all cell types, reflecting its function as a general neuronal marker involved in synaptic transmission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Statistics for electrophysiological features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features overview\n",
    "\n",
    "# List of cleaned electrophysiological features retained for analysis\n",
    "ephysNames_filtered = ephysNames[\n",
    "    ~np.isin(ephysNames, features_exclude)\n",
    "]  # see above\n",
    "\n",
    "print(\n",
    "    \"Remaining electrophysiological features (n = {}) for analysis\".format(\n",
    "        len(ephysNames_filtered)\n",
    "    )\n",
    ")\n",
    "for i, name in enumerate(ephysNames_filtered, 1):\n",
    "    print(f\"{i:2d}. {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descriptive statistics of ephysiological features (keep in mind that data is already standardized)\n",
    "\n",
    "# print(\n",
    "#    \"Number of cells with ephys data: \",\n",
    "#    np.sum(np.isin(cells, ephysCells)),\n",
    "# )\n",
    "\n",
    "# dictionary to collect stats\n",
    "stats_dict = {\n",
    "    \"Mean\": [],\n",
    "    \"Std\": [],\n",
    "    \"Min\": [],\n",
    "    \"Max\": [],\n",
    "    \"Median\": [],\n",
    "    \"Skewness\": [],\n",
    "}\n",
    "\n",
    "# Compute stats per feature\n",
    "### replace all Xs with ephysData_filtered\n",
    "# for i in range(X.shape[1]):\n",
    "for i in range(ephysData_filtered.shape[1]):\n",
    "    # data = X[:, i]\n",
    "    data = ephysData_filtered[:, i]\n",
    "\n",
    "    # Collect statistics\n",
    "    stats_dict[\"Mean\"].append(np.mean(data))\n",
    "    stats_dict[\"Std\"].append(np.std(data))\n",
    "    stats_dict[\"Min\"].append(np.min(data))\n",
    "    stats_dict[\"Max\"].append(np.max(data))\n",
    "    stats_dict[\"Median\"].append(np.median(data))\n",
    "    stats_dict[\"Skewness\"].append(stats.skew(data))\n",
    "\n",
    "# Convert to DataFrame\n",
    "feature_stats_df = pd.DataFrame(stats_dict, index=ephysNames_filtered)\n",
    "\n",
    "print(\"Basic statistics of electrophysiological features (standardized):\")\n",
    "display(feature_stats_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Interpretation:*\n",
    "\n",
    "Overall:\n",
    "* mean and standard deviation are (roughly) 0 and 1, respectively, as the data is standardized\n",
    "* Min/Max values show range in z-score units\n",
    "\n",
    "Mentionable Observations:\n",
    "* ISI adaptation index (ske=2.48), Rebound (mV) (2.05), Sag ratio (+2.06), and Rheobase (pA) (+1.64) are strongly right-skew, indicating that most cells have low values, but a smaller subset show much higher values.\n",
    "* AP amplitude adaptation index (skew = -1.13) are left-skewed, indicating that most cells have high values (i.e. high adaptation), but a smaller subset show much lower values.\n",
    "* Membrane time constant, Input resistance, and Max number of APs have high max values (>3.8 z-score), indicating large variability among cells in how they respond to current input.\n",
    "* Several features show approximately symmetric distributions, like AP threshold (skew = −0.06), Afterhyperpolarization (mV) (skew = +0.03) and Resting membrane potential (skew = −0.12). This suggests that these properties are well-centered and consistent across cells.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = len(ephysNames_filtered)\n",
    "n_cols = 4  # Number of columns in the grid\n",
    "n_rows = int(\n",
    "    np.ceil(n_features / n_cols)\n",
    ")  # Number of rows in the grid, rounded up\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 4, n_rows * 3))\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feature in enumerate(ephysNames_filtered):\n",
    "    ax = axes[i]\n",
    "    sns.histplot(\n",
    "        # X[:, i],\n",
    "        ephysData_filtered[:, i],\n",
    "        bins=30,\n",
    "        kde=True,\n",
    "        color=\"skyblue\",\n",
    "        stat=\"density\",\n",
    "        ax=ax,\n",
    "    )\n",
    "    sns.kdeplot(\n",
    "        # X[:, i], color=\"darkblue\", linewidth=1, ax=ax\n",
    "        ephysData_filtered[:, i],\n",
    "        color=\"darkblue\",\n",
    "        linewidth=1,\n",
    "        ax=ax,\n",
    "    )  # smoothed density plot (darkblue line)\n",
    "\n",
    "    ax.axvline(0, color=\"red\", linestyle=\"--\", linewidth=1)\n",
    "    ax.set_title(feature, fontsize=9, fontweight=\"bold\")\n",
    "    ax.set_xlabel(\"Standardized value\")\n",
    "    ax.set_ylabel(\"Density\")\n",
    "\n",
    "# Remove empty subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "fig.suptitle(\n",
    "    \"Distributions of Standardized Electrophysiological Features\",\n",
    "    fontsize=14,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Interpretation:*\n",
    "* means (0) and standard deviations (1) are consistent with standardized data\n",
    "* skewness is clearly visible\n",
    "* generally, the distributions show clearly what the statistics suggest: all features are centered around zero with unit variance, and the observed skewness in the plots aligns with the computed skewness values, highlighting the diversity in distribution shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame with standardized ephys data\n",
    "# ephys_df = pd.DataFrame(X, columns=ephysNames_filtered)\n",
    "ephys_df = pd.DataFrame(ephysData_filtered, columns=ephysNames_filtered)\n",
    "\n",
    "# Compute Pearson correlation matrix\n",
    "corr_matrix = ephys_df.corr()\n",
    "\n",
    "# Test\n",
    "print(\"Correlation matrix shape:\", corr_matrix.shape)\n",
    "\n",
    "# \"high correlation\" threshold\n",
    "threshold = 0.6  # whats the best value?\n",
    "high_corr_pairs = []\n",
    "\n",
    "# Iterate over the upper triangle of the correlation matrix (excluding the diagonal) because the matrix is symmetric\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i + 1, len(corr_matrix.columns)):\n",
    "        corr_value = corr_matrix.iloc[i, j]\n",
    "        if abs(corr_value) > threshold:\n",
    "            feature_i = corr_matrix.columns[i]\n",
    "            feature_j = corr_matrix.columns[j]\n",
    "            high_corr_pairs.append((feature_i, feature_j, corr_value))\n",
    "\n",
    "# Print results\n",
    "print(\n",
    "    \"Feature pairings with high correlations (|corr| > {:.2f}):\".format(\n",
    "        threshold\n",
    "    )\n",
    ")\n",
    "for feature1, feature2, corr in sorted(\n",
    "    high_corr_pairs, key=lambda x: -abs(x[2])\n",
    "):\n",
    "    print(f\"{feature1:30s} x {feature2:30s}: {corr:+.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the correlation matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(\n",
    "    # sns.clustermap(  # clustermap clusters features based on correlation, kann einkommentiert werden\n",
    "    corr_matrix,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cmap=\"vlag\",\n",
    "    center=0,\n",
    "    square=True,\n",
    "    linewidths=0.5,\n",
    "    cbar_kws={\"shrink\": 0.8},\n",
    ")\n",
    "plt.title(\"Pairwise Pearson Correlation of Electrophysiological Features\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Interpretation:*\n",
    "\n",
    "Positive correlations:\n",
    "* AP width (ms) x Upstroke-to-downstroke ratio: +0.94. Suggests these may capture overlapping aspects of action potential shape.\n",
    "* Afterhyperpolarization (mV) x Upstroke-to-downstroke ratio: +0.67. Larger APs may lead to deeper afterhyperpolarizations, consistent with biophysical expectations\n",
    "* AP amplitude (mV) x Afterhyperpolarization (mV): +0.67. Larger APs may lead to deeper afterhyperpolarizations, possibly reflecting cell type-specific properties or biophysical mechanisms.\n",
    "\n",
    "Negative correlations:\n",
    "* AP width (ms) x Max number of APs: -0.73. Cells firining more APs tend to have narrower APs, possibly indicating a trade-off between firing rate and action potential width.\n",
    "* ISI coefficient of variation x Max number of APs: -0.70. More consistent ISIs are found in cells with higher firing rates, hinting at firing pattern specialization.\n",
    "* Max number of APs x Upstroke-to-downstroke ratio: -0.68. Suggests that cells with more APs tend to have lower upstroke-to-downstroke ratios, possibly indicating differences in firing patterns or cell types.\n",
    "\n",
    "Generally, highly correlated features might be redundant or be functionally related, which will be the main part of the next tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Investigate Ground Truth Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze and visualize ground truth distribution\n",
    "# ground truth data:\n",
    "# - rna_type: 77 trancriptomic subtypes\n",
    "# - rna_family: 9 broader transcriptomic families\n",
    "\n",
    "# Barplot of RNA types\n",
    "rna_type_counts = pd.Series(rna_type).value_counts()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.barplot(\n",
    "    x=rna_type_counts.index,\n",
    "    y=rna_type_counts.values,\n",
    "    hue=rna_type_counts.index,\n",
    "    palette=\"muted\",\n",
    "    dodge=False,\n",
    "    legend=False,\n",
    ")\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"RNA Types by Cell Count\")\n",
    "plt.ylabel(\"Number of Cells\")\n",
    "plt.xlabel(\"RNA Type\")\n",
    "# plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Barplot of RNA families\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.countplot(\n",
    "    x=rna_family,\n",
    "    hue=rna_family,\n",
    "    order=np.unique(rna_family),\n",
    "    palette=\"Set2\",\n",
    "    legend=False,\n",
    ")\n",
    "plt.title(\"Distribution of RNA Families\")\n",
    "plt.ylabel(\"Number of Cells\")\n",
    "plt.xlabel(\"RNA Family\")\n",
    "plt.xticks(rotation=45)\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Interpretation:*\n",
    "\n",
    "Top: RNA types by cell count\n",
    "* barplot shows the number of cells annotated with each RNA type\n",
    "* only a few rna types are considerably highly represented (e.g.Pvalb Itrap2, L2/3 IT_2/)\n",
    "* many RNA types have fewer than 10 cells, suggesting class imbalance --> could impact clustering and classification methods \n",
    "\n",
    "Bottom: RNA Families by cell count\n",
    "* the plot aggregates rna types into broader families, which are essentially coarser labels\n",
    "* Families like IT, Pvalb and Sst are dominating, whereas others like NP and Sncp are very underrepresented\n",
    "* Compared to the top plot, the family distribution is more balanced, with fewer families having very few cells, yet the class imbalance is still present\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print metadata labels\n",
    "print(\"Metadata labels:\")\n",
    "for col in meta.columns:\n",
    "    print(f\"- {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: das sollten wir nochmal überarbeiten bzw. genauer formulieren**\n",
    "\n",
    "\n",
    "Generally, we want to focus on metadata that improves analysis quality. Not all recorded metadata is useful for our purposes, so we will focus on the following features:\n",
    "* sequencing batch - technical batch effects can confound biological signals, so we will use this to control for batch effects in our analyses\n",
    "* targeted layer\n",
    "* inferred layer\n",
    "* soma depth\n",
    "* cortical thickness\n",
    "* cre lines\n",
    "\n",
    "Specifically interesting:\n",
    "\n",
    "Cre Line:\n",
    "* Cre lines indicate genetic targeting strategies, which can enrich for specific neuron types\n",
    "* They help validate whether observed patterns are biologically driven or due to experimental targeting\n",
    "\n",
    "Inferred layer:\n",
    "* Cortical layers correspond to distinct cell populations and functions; many electrophysiological and transcriptomic differences are layer-specific.\n",
    "* It could serve as a meaningful covariate or stratification variable\n",
    "\n",
    "Sequencing batch:\n",
    "* Sequencing batch can introduce technical variability (batch effects) unrelated to biology\n",
    "* Identifying batch effects can help to avoid spurious conclusions and ensure generalizability\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Cre lines\n",
    "cre_counts = meta[\"Cre\"][exclude_low_quality].value_counts()\n",
    "print(\"Cre line distribution:\\n\", cre_counts)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.countplot(\n",
    "    y=meta[\"Cre\"][exclude_low_quality],\n",
    "    order=cre_counts.index,\n",
    "    palette=\"muted\",\n",
    "    hue=meta[\"Cre\"][exclude_low_quality],\n",
    "    legend=False,\n",
    ")\n",
    "plt.title(\"Distribution of Cre Lines\")\n",
    "plt.xlabel(\"Cell Count\")\n",
    "plt.ylabel(\"Cre Line\")\n",
    "# plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Cross-tab with RNA type\n",
    "# cre_rna_crosstab = pd.crosstab(meta[\"Cre\"][exclude_low_quality], rna_type)\n",
    "# print(\"Cre Line vs RNA Type Crosstab:\")\n",
    "# display(cre_rna_crosstab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution\n",
    "layer_counts = meta[\"Inferred layer\"][exclude_low_quality].value_counts()\n",
    "print(\"Inferred layer distribution:\\n\", layer_counts)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.countplot(\n",
    "    x=meta[\"Inferred layer\"][exclude_low_quality],\n",
    "    order=layer_counts.index,\n",
    "    palette=\"coolwarm\",\n",
    "    hue=meta[\"Inferred layer\"][exclude_low_quality],\n",
    "    legend=False,\n",
    ")\n",
    "plt.title(\"Distribution of Inferred Cortical Layers\")\n",
    "plt.xlabel(\"Inferred Layer\")\n",
    "plt.ylabel(\"Number of Cells\")\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of batches\n",
    "batch_counts = meta[\"Sequencing batch\"][exclude_low_quality].value_counts()\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.barplot(\n",
    "    x=batch_counts.index.astype(str),\n",
    "    y=batch_counts.values,\n",
    "    palette=\"coolwarm\",\n",
    "    hue=batch_counts.index.astype(str),\n",
    "    legend=False,\n",
    ")\n",
    "plt.title(\"Distribution of Sequencing Batches\")\n",
    "plt.xlabel(\"Sequencing Batch\")\n",
    "plt.ylabel(\"Cell Count\")\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metadata Conclusions\n",
    "\n",
    "Cre Lines:\n",
    "* The distribution shows several dominant lines (e.g. SST+, PV+), with many others represented sparsely.\n",
    "* A large number of unique Cre lines suggests some are too underrepresented for individual modeling but may help explain biological variability when grouped or used selectively.\n",
    "\n",
    "Inferred layer:\n",
    "* The distribution is uneven, with most cells in layer 5, followed by 2/3 and 6, and very few in layer 1.\n",
    "* This may impact how well certain layers are represented in modeling, and highlights that layer-specific trends could be explored in later tasks.\n",
    "\n",
    "Sequencing batch:\n",
    "* The barplot revealed an uneven distribution across batches, ranging from very large (e.g. batch 8) to tiny (batch 12).\n",
    "* \n",
    "\n",
    "**How they could be used in further analyses?:**\n",
    "\n",
    "Cre Lines:\n",
    "* use after clustering --> compare predicted clusters to Cre line distributions\n",
    "* helps biologically validate clusters, e.g. a cluster dominated by SST+ Cre lines might represents inhibitory neurons (task 4)\n",
    "* can examine how cre lines associate with PCs or gene expression signatures (task 5)\n",
    "\n",
    "Inferred layer:\n",
    "* use inferred layer as a coloring option to see if spatial cell identity is reflected in transcriptomic space (task 3)\n",
    "* could be added as a covariate or group in regression or correlation analyses to see how gen-PC correlations differ across layers (task 5)\n",
    "\n",
    "Sequencing batch:\n",
    "* use batch information to check for batch effects after normalization and transformation \n",
    "* could color 2D visualizations (e.g. PCA/t-SNE) by batch to visually inspect clustering by batch, which is undesired and indicates technical confounding (task 2)\n",
    "* use batch labels as negative control labels: ideally batches should not be separable in a meaningful embedding (task 3)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparation steps\n",
    "# we want to use meta data\n",
    "# therefore we need to filter the metadata to only include the cells we are interested in\n",
    "# this is done by excluding the low quality cells which is only already done for rna_type and rna_family\n",
    "# this was already done for exonCounts\n",
    "# to avoid misalignment, we reset indices so that the indices of the meta data match the indices of the exonCounts\n",
    "\n",
    "# RNA counts\n",
    "exonCounts_filtered = exonCounts\n",
    "# könnte man sich sparen, da exonCounts schon gefiltert ist, aber so ist es konsistent mit den anderen Variablen\n",
    "\n",
    "# Ground truth labels\n",
    "rna_type_filtered = rna_type.reset_index(drop=True)\n",
    "rna_family_filtered = rna_family.reset_index(drop=True)\n",
    "\n",
    "# Filter Metadata variables of interest\n",
    "cre_filtered = meta[\"Cre\"][exclude_low_quality].reset_index(drop=True)\n",
    "layer_filtered = meta[\"Inferred layer\"][exclude_low_quality].reset_index(\n",
    "    drop=True\n",
    ")\n",
    "batch_filtered = meta[\"Sequencing batch\"][exclude_low_quality].reset_index(\n",
    "    drop=True\n",
    ")\n",
    "\n",
    "assert (\n",
    "    exonCounts_filtered.shape[0]\n",
    "    == len(rna_type_filtered)\n",
    "    == len(cre_filtered)\n",
    "    == len(layer_filtered)\n",
    "    == len(batch_filtered)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 normalization + transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "log-CPM normalization - appropriately tailored for read count data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### M: ich pass die variablen mal an\n",
    "\n",
    "# exonCounts.shape = (n_cells, n_genes)\n",
    "# genes = list of gene names\n",
    "# rna_types = list of cell names (?)\n",
    "\n",
    "# compute total amount of reads per cell\n",
    "total_counts_per_cell = exonCounts_filtered.sum(axis=1)\n",
    "\n",
    "# avoid dividing by zero by setting any 0s to 1\n",
    "total_counts_per_cell[total_counts_per_cell == 0] = 1\n",
    "\n",
    "# calculate counts per million => normalizes cells to be able to compare them\n",
    "cpm = (\n",
    "    exonCounts_filtered.T / total_counts_per_cell\n",
    ").T * 1e6  # transpose to divide along columns (genes)\n",
    "\n",
    "# log-transform with log(1+x) => squash the numbers\n",
    "log_cpm = np.log1p(cpm)\n",
    "\n",
    "# create dataframe\n",
    "log_cpm_df = pd.DataFrame(log_cpm, index=rna_type_filtered, columns=genes)\n",
    "\n",
    "print(\"Normalization complete. Log-CPM shape:\", log_cpm.shape)\n",
    "assert log_cpm_df.shape[0] == len(rna_type_filtered), \"check for alignment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show how normalization changes total RNA counts\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "axes[0].bar(\n",
    "    range(len(total_counts_per_cell)),\n",
    "    total_counts_per_cell,\n",
    "    width=1,\n",
    "    alpha=0.5,\n",
    "    color=\"blue\",\n",
    ")\n",
    "axes[0].set_yscale(\"log\")\n",
    "axes[0].set_xlabel(\"Cell index\")\n",
    "axes[0].set_ylabel(\"Raw RNA counts\")\n",
    "axes[0].set_title(\"Total RNA Counts Per Cell\")\n",
    "\n",
    "# log_cpm_df.shape = (n_cells, n_genes)\n",
    "total_cpm_counts_per_cell = cpm.sum(axis=1)\n",
    "\n",
    "\n",
    "axes[1].bar(\n",
    "    range(len(total_cpm_counts_per_cell)),\n",
    "    total_cpm_counts_per_cell,\n",
    "    width=1,\n",
    "    alpha=0.5,\n",
    "    color=\"blue\",\n",
    ")\n",
    "axes[1].set_yscale(\"log\")\n",
    "axes[1].set_xlabel(\"Cell index\")\n",
    "axes[1].set_ylabel(\"Normalized RNA counts\")\n",
    "axes[1].set_title(\"Total Normalized RNA Counts Per Cell\")\n",
    "\n",
    "# show the effect of log-transform # weiß nich ob wir das wollen/brauchen\n",
    "\"\"\"log_cpm_mean_per_cell = log_cpm_df.mean(axis=1)\n",
    "\n",
    "axes[2].bar(\n",
    "    range(len(log_cpm_mean_per_cell)),\n",
    "    log_cpm_mean_per_cell,\n",
    "    width=1,\n",
    "    alpha=0.5,\n",
    "    color=\"blue\",\n",
    ")\n",
    "axes[2].set_yscale(\"log\")\n",
    "axes[2].set_xlabel(\"Cell index\")\n",
    "axes[2].set_ylabel(\"log1p(CPM) values per cell\")\n",
    "axes[2].set_title(\"Distribution of log1p(CPM) values per cell\")\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> the raw counts are larger numbers whereas the log-CPM shows a compressed scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show change after log transform to tackle the unstable variance\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "axes[0].scatter(\n",
    "    mean_expression_across_cells,\n",
    "    variance_expression_across_cells,\n",
    "    s=5,\n",
    "    alpha=0.5,\n",
    ")\n",
    "axes[0].set_xscale(\"log\")\n",
    "axes[0].set_yscale(\"log\")\n",
    "axes[0].set_xlabel(\"Mean Expression Across Cells (log scale)\")\n",
    "axes[0].set_ylabel(\"Variance Across Cells (log scale)\")\n",
    "axes[0].set_title(\"Mean vs Variance of Gene Expression (log scale)\")\n",
    "\n",
    "\n",
    "mean_log_expression = log_cpm.mean(axis=0)\n",
    "var_log_expression = log_cpm.var(axis=0)\n",
    "\n",
    "\n",
    "axes[1].scatter(\n",
    "    mean_log_expression,\n",
    "    var_log_expression,\n",
    "    s=5,\n",
    "    alpha=0.5,\n",
    ")\n",
    "axes[1].set_xscale(\"log\")\n",
    "axes[1].set_yscale(\"log\")\n",
    "axes[1].set_xlabel(\"Mean Expression Across Cells (log scale)\")\n",
    "axes[1].set_ylabel(\"Variance Across Cells (log scale)\")\n",
    "axes[1].set_title(\n",
    "    \"Mean vs Variance of Gene Expression After Transform (log scale)\"\n",
    ")\n",
    "x_vals = np.linspace(1e-3, 1e4, 100)  # log scale range\n",
    "axes[0].plot(\n",
    "    x_vals, x_vals, linestyle=\"--\", color=\"red\", label=\"variance = mean\"\n",
    ")\n",
    "x_vals = np.linspace(1e-4, 1e1, 100)  # log scale range\n",
    "axes[1].plot(\n",
    "    x_vals, x_vals, linestyle=\"--\", color=\"red\", label=\"variance = mean\"\n",
    ")\n",
    "axes[0].legend()\n",
    "axes[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> sieht das so gut aus? lol (vgl. folie 34 von foliensatz 7)\n",
    "\n",
    "M: würde sagen ja, in der aufgabenstellung zu task1 steht ja auch: \"Keep in mind that the RNA data in this project is read counts, not UMI counts, so it is not supposed to follow a Poisson distribution.\" \n",
    "--> würde dann einfach eine interpretation wie im nächsten Absatz schreiben\n",
    "\n",
    "The red dashed lines are identity lines for reference, representing the expected relationship for a Poisson process, where variability is solely due to sampling noise. Genes above the line are more variable than expected under a Poisson model, indicating that there is biological signal instead of just noise. That seems to be the case for almost all of the genes, which is common in raw count data due to both biological variablity and noise.\n",
    "\n",
    "The log transformation compresses large values and stabilizes variance, which resulted in a more symmetrical distribution of the genes around the identity line. This helps to better distinguish signal from noise: The genes above the line seem to be the one carrying meaningful biological signal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Interpretation:*\n",
    "\n",
    "Left: Raw CPM (before log transformation)\n",
    "* variance increases rapidly with mean, indicating overdispersion\n",
    "* many genes show much higher variance than mean, deviating strongly from the Poisson assumption variance = mean. But this is expected for raw count data, as it is not supposed to follow a Poisson distribution.\n",
    "* Strong heteroskedasticity (variance depends on the magnitude of the mean). Could hint that PCA might not be the best choice for this data, as PCA assumes homoskedasticity (constant variance across all means).\n",
    "\n",
    "Right: after log transformation\n",
    "* cloud of points is more compact, with less spread in variance for high means\n",
    "* points are now more evenly distributed around the identity line, indicating that the log transformation has stabilized variance and made the data more homoskedastic (e.g. compress extreme values and reduce skew)\n",
    "* log transformed data looks now more suitable for PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 select genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask out genes with zero mean\n",
    "# M: sollte das mask_raw sein?\n",
    "expression_mask = mean_expression_across_cells > 0.1\n",
    "mask_raw = expression_mask\n",
    "\n",
    "# compute fano factor for raw counts or cpm\n",
    "fano = (\n",
    "    variance_expression_across_cells[mask_raw]\n",
    "    / mean_expression_across_cells[mask_raw]\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# plot raw data fano\n",
    "axes[0].scatter(\n",
    "    mean_expression_across_cells[mask_raw],\n",
    "    fano,\n",
    "    s=5,\n",
    "    alpha=0.5,\n",
    ")\n",
    "axes[0].set_xscale(\"log\")\n",
    "axes[0].set_yscale(\"log\")\n",
    "axes[0].set_xlabel(\"Mean Expression Across Cells\")\n",
    "axes[0].set_ylabel(\"Fano Factor (Var / Mean)\")\n",
    "axes[0].set_title(\"Fano Factor\")\n",
    "\n",
    "# plot variance vs mean\n",
    "mask_log = mean_log_expression > 0\n",
    "axes[1].scatter(\n",
    "    mean_log_expression[mask_log],\n",
    "    var_log_expression[mask_log],\n",
    "    s=5,\n",
    "    alpha=0.5,\n",
    ")\n",
    "axes[1].set_xscale(\"log\")\n",
    "axes[1].set_yscale(\"log\")\n",
    "axes[1].set_xlabel(\"Mean (log CPM)\")\n",
    "axes[1].set_ylabel(\"Variance (log CPM)\")\n",
    "axes[1].set_title(\"Variance vs Mean After Log Transform\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Interpretation:*\n",
    "\n",
    "Left:\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose highly variable genes (hvgs) from normalized data\n",
    "# we DO NOT use log-transformed data here, since that would flatten the mean-variance relationship\n",
    "# (and we want to find the genes with high absolute variance)\n",
    "dispersion = variance_expression_across_cells / (\n",
    "    mean_expression_across_cells + 1e-8\n",
    ")\n",
    "\n",
    "# remove genes with very low mean (avoid divide by zero)\n",
    "filtered_dispersion = dispersion[mask_raw]\n",
    "filtered_mean = mean_expression_across_cells[mask_raw]\n",
    "\n",
    "# play with the number of selected genes:\n",
    "# n_top_genes = 2000\n",
    "# n_top_genes = 1000\n",
    "n_top_genes = 500\n",
    "\n",
    "# 2000 HVGs is the most common default, but even 1000 lead to a very high necessary number of principle components in PCA later on.\n",
    "# Fewer than 500 HVGs risks missing subtle biological signals, so we chose 500 as the lowest \"possible\" number.\n",
    "\n",
    "top_indices = np.argsort(filtered_dispersion)[-n_top_genes:]\n",
    "\n",
    "# get gene names\n",
    "hvg_genes = np.array(genes)[mask_raw][top_indices]\n",
    "\n",
    "# print(hvg_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot mean-variance with hvgs highlighted\n",
    "\n",
    "# mask of genes that are in hvg list\n",
    "is_hvg = np.isin(genes, hvg_genes)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "\n",
    "# all genes\n",
    "ax.scatter(\n",
    "    mean_expression_across_cells[mask_raw],\n",
    "    variance_expression_across_cells[mask_raw],\n",
    "    s=5,\n",
    "    alpha=0.4,\n",
    "    label=\"all genes\",\n",
    "    color=\"lightblue\",\n",
    ")\n",
    "\n",
    "# overlay HVGs\n",
    "ax.scatter(\n",
    "    mean_expression_across_cells[is_hvg],\n",
    "    variance_expression_across_cells[is_hvg],\n",
    "    s=10,\n",
    "    alpha=0.7,\n",
    "    # label=\"HVGs\",\n",
    "    label=f\"Top {n_top_genes} HVGs by dispersion\",\n",
    "    color=\"darkblue\",\n",
    ")\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xlabel(\"Mean Expression Across Cells\")\n",
    "ax.set_ylabel(\"Variance Across Cells\")\n",
    "ax.set_title(\"HVGs Highlighted in Mean–Variance Plot\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# TODO (?) Add a legend explaining HVG criteria (e.g. “top 2000 by dispersion”)\n",
    "# M: Fixed it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 PCA\n",
    "\n",
    "note: use normalized + log-transformed data here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find indices of HVGs\n",
    "hvg_indices = np.where(np.isin(genes, hvg_genes))[0]\n",
    "\n",
    "# subset the expression matrix: shape = (cells, HVGs)\n",
    "hvg_expression = exonCounts[:, hvg_indices]\n",
    "\n",
    "# use normalized + log-transformed data from before\n",
    "log_cpm_df\n",
    "log_hvg_df = log_cpm_df.iloc[:, hvg_indices].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# fit PCA + play with the number of components TODO!\n",
    "pca = PCA(\n",
    "    n_components=55  # we chose the lowest possible number to still explain at least 50% of variance\n",
    ")\n",
    "X_pca = pca.fit_transform(log_hvg_df)\n",
    "\n",
    "print(\"PCA result shape:\", X_pca.shape)  # (num_cells, n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot explained variance (?? unsicher ob nötig)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "explained = pca.explained_variance_ratio_\n",
    "plt.plot(np.cumsum(explained))\n",
    "plt.xlabel(\"Number of Components\")\n",
    "plt.ylabel(\"Cumulative Explained Variance\")\n",
    "plt.title(\"Explained Variance by PCA Components\")\n",
    "plt.axhline(0.6, color=\"red\", label=\"50% threshold\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 1000 HVGs, 390 components would be needed to capture ~90% of the variance. This means that the variance is spread out across many dimensions and most individual PCs explain only a small amount of variance. Even though more PCs can capture more information, most of that may not be biologically meaningful, so choosing around 20-50 PCs makes more sense.\n",
    "\n",
    "**M: glaube wenn man hier von 1000 HVGs spricht, dann sollte man vlt auch die zahlen printen oder explained variance plot zeigen. könnte ja auch mehrere plots nebeneinander machen (z.b. 2x2) für die versch. anzahl and HVGs?**\n",
    "\n",
    "With 25 PCs, we only capture about 50% of explained variance, but it’s better to retain fewer PCs that reflect meaningful signal than to overfit with noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the first 2 components\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], s=5, alpha=0.6)\n",
    "\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.title(\"PCA on Highly Variable Genes\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 5))\n",
    "sns.scatterplot(\n",
    "    x=X_pca[:, 0],\n",
    "    y=X_pca[:, 1],\n",
    "    hue=rna_type,\n",
    "    s=40,\n",
    "    alpha=0.7,\n",
    "    legend=False,\n",
    "    palette=\"tab20\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### N: hier nochmal kompakt mit parametern variiert. das zeigt genau gar keine veränderung?? wie soll man die im 2D überhaupt sehen??\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Set parameters\n",
    "hvg_counts = [500, 1000, 2000]\n",
    "pca_components = [15, 25, 50]\n",
    "\n",
    "# Set up figure\n",
    "fig, axes = plt.subplots(\n",
    "    len(hvg_counts), len(pca_components), figsize=(15, 10)\n",
    ")\n",
    "fig.suptitle(\n",
    "    \"Effect of HVG Count and PCA Components on 2D Projection\", fontsize=16\n",
    ")\n",
    "\n",
    "# Loop through combinations\n",
    "for i, n_hvg in enumerate(hvg_counts):\n",
    "    # Compute dispersion for HVG selection\n",
    "    dispersion = variance_expression_across_cells / (\n",
    "        mean_expression_across_cells + 1e-8\n",
    "    )\n",
    "    mask = mean_expression_across_cells > 0.1  # Or use your expression mask\n",
    "    filtered_dispersion = dispersion[mask]\n",
    "    top_indices = np.argsort(filtered_dispersion)[-n_hvg:]\n",
    "    hvg_genes = np.array(genes)[mask][top_indices]\n",
    "\n",
    "    # Subset and standardize log-CPM data\n",
    "    log_hvg_df = log_cpm_df[hvg_genes]\n",
    "    data = StandardScaler().fit_transform(log_hvg_df.values)\n",
    "\n",
    "    for j, n_pc in enumerate(pca_components):\n",
    "        pca = PCA(n_components=n_pc)\n",
    "        X_pca = pca.fit_transform(data)\n",
    "\n",
    "        ax = axes[i, j]\n",
    "        scatter = ax.scatter(\n",
    "            X_pca[:, 0],\n",
    "            X_pca[:, 1],\n",
    "            c=None,  # optionally: use label encoding of rna_type for colors\n",
    "            s=10,\n",
    "            alpha=0.6,\n",
    "        )\n",
    "\n",
    "        ax.set_title(f\"{n_hvg} HVGs | {n_pc} PCs\")\n",
    "        ax.set_xlabel(\"PC1\")\n",
    "        ax.set_ylabel(\"PC2\")\n",
    "\n",
    "# Clean layout\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install umap-learn scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign column names to ephysData_filtered\n",
    "#### hab ich das vorher übersehen dass das schon gemacht wurde??\n",
    "\n",
    "ephys_df = pd.DataFrame(ephysData_filtered, columns=ephysNames_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "log_hvg_df = log_cpm_df[hvg_genes]\n",
    "X_hvg = StandardScaler().fit_transform(log_hvg_df.values)\n",
    "\n",
    "# filter log-normalized gene expression to the same 1224 cells\n",
    "X_hvg_filtered = X_hvg[keepcells, :]  ### hier dann gar nicht verwendet?\n",
    "\n",
    "# Define dimensionality reduction methods and parameters\n",
    "methods = {\n",
    "    \"t-SNE (perp=5)\": {\n",
    "        \"func\": lambda X: TSNE(\n",
    "            n_components=2, perplexity=5, max_iter=1000, random_state=42\n",
    "        ).fit_transform(X)\n",
    "    },\n",
    "    \"t-SNE (perp=30)\": {\n",
    "        \"func\": lambda X: TSNE(\n",
    "            n_components=2, perplexity=30, max_iter=1000, random_state=42\n",
    "        ).fit_transform(X)\n",
    "    },\n",
    "    \"t-SNE (perp=100)\": {\n",
    "        \"func\": lambda X: TSNE(\n",
    "            n_components=2, perplexity=100, max_iter=1000, random_state=42\n",
    "        ).fit_transform(X)\n",
    "    },\n",
    "}\n",
    "\n",
    "# Create subplots\n",
    "n_methods = len(methods)\n",
    "fig, axes = plt.subplots(1, n_methods, figsize=(5 * n_methods, 5))\n",
    "\n",
    "# Loop through and plot\n",
    "for ax, (title, conf) in zip(axes, methods.items()):\n",
    "    X_embedded = conf[\"func\"](X_hvg)\n",
    "\n",
    "    sns.scatterplot(\n",
    "        x=X_embedded[:, 0],\n",
    "        y=X_embedded[:, 1],\n",
    "        hue=rna_family,\n",
    "        # hue=rna_type,  # color by cell type\n",
    "        # c=ephys_df[\"AP width (ms)\"],  # v1\n",
    "        # c=ephys_df[\"Max number of APs\"],  # v2\n",
    "        # c=ephys_df[\"AP amplitude (mV)\"],  # v3\n",
    "        # c=ephys_df[\"Latency (ms)\"],  # v4\n",
    "        palette=\"tab10\",\n",
    "        # cmap=\"inferno\",  # change colormap here\n",
    "        s=30,\n",
    "        alpha=0.7,\n",
    "        legend=False,\n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Dim 1\")\n",
    "    ax.set_ylabel(\"Dim 2\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The comparison shows how t-SNE's perplexity parameter affects local versus global structure:\n",
    "* perplexity=5: clusters are small and tightly packed => emphasis on fine local relationships\n",
    "* perplexity=30: balance between local detail & global structure => seems to provide the best overview of the data\n",
    "* perplexity=100: the plot appears more globally smoothed and there is less distinct clustering => highlighting broader structure at the expense of local detail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dimensionality reduction methods and parameters\n",
    "methods = {\n",
    "    \"UMAP (n=15)\": {\n",
    "        \"func\": lambda X: umap.UMAP(\n",
    "            n_neighbors=15, min_dist=0.1, random_state=42\n",
    "        ).fit_transform(X)\n",
    "    },\n",
    "    \"UMAP (n=30)\": {\n",
    "        \"func\": lambda X: umap.UMAP(\n",
    "            n_neighbors=30, min_dist=0.3, random_state=42\n",
    "        ).fit_transform(X)\n",
    "    },\n",
    "    \"UMAP (n=50)\": {\n",
    "        \"func\": lambda X: umap.UMAP(\n",
    "            n_neighbors=50, min_dist=0.3, random_state=42\n",
    "        ).fit_transform(X)\n",
    "    },\n",
    "}\n",
    "\n",
    "# Create subplots\n",
    "n_methods = len(methods)\n",
    "fig, axes = plt.subplots(1, n_methods, figsize=(5 * n_methods, 5))\n",
    "\n",
    "# Loop through and plot\n",
    "for ax, (title, conf) in zip(axes, methods.items()):\n",
    "    X_embedded = conf[\"func\"](X_hvg)\n",
    "\n",
    "    sns.scatterplot(\n",
    "        x=X_embedded[:, 0],\n",
    "        y=X_embedded[:, 1],\n",
    "        hue=rna_family,\n",
    "        # hue=rna_type,  # color by cell type\n",
    "        # c=ephys_df[\"AP width (ms)\"],  # v1\n",
    "        # c=ephys_df[\"Max number of APs\"],  # v2\n",
    "        # c=ephys_df[\"AP amplitude (mV)\"],  # v3\n",
    "        # c=ephys_df[\"Latency (ms)\"],  # v4\n",
    "        palette=\"tab10\",\n",
    "        # cmap=\"inferno\",  # change colormap here\n",
    "        s=30,\n",
    "        alpha=0.7,\n",
    "        legend=False,\n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Dim 1\")\n",
    "    ax.set_ylabel(\"Dim 2\")\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.title(\"UMAP with different n, colored according to AP width\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The comparison shows how the 'n_neighbors' parameter affects the balance between local and global structure:\n",
    "\n",
    "n=15: the plot reveals finer substructures and potential cell states\n",
    "\n",
    "n=30 / n=50:\n",
    "* clusters are more connected or blended.\n",
    "* increasing `n_neighbors` favors global structure, but makes us lose finer distinctions\n",
    "* useful to highlight broad cell types instead of subtypes\n",
    "\n",
    "=> smaller 'n_neighbors' values are better for identifying subpopulations, while larger values show more global cell type structure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3 visual comparison of PCA, t-SNE, UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import umap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Prepare your data\n",
    "# log_hvg_df = log_cpm_df[hvg_genes]\n",
    "# X = StandardScaler().fit_transform(log_hvg_df.values)\n",
    "\n",
    "# Define dimensionality reduction methods and parameters\n",
    "methods = {\n",
    "    \"PCA\": {\"func\": lambda X: PCA(n_components=2).fit_transform(X)},\n",
    "    \"t-SNE (perp=30)\": {\n",
    "        \"func\": lambda X: TSNE(\n",
    "            n_components=2, perplexity=30, max_iter=1000, random_state=42\n",
    "        ).fit_transform(X)\n",
    "    },\n",
    "    \"UMAP (n=15)\": {\n",
    "        \"func\": lambda X: umap.UMAP(\n",
    "            n_neighbors=15, min_dist=0.1, random_state=42\n",
    "        ).fit_transform(X)\n",
    "    },\n",
    "}\n",
    "\n",
    "# Create subplots\n",
    "n_methods = len(methods)\n",
    "fig, axes = plt.subplots(1, n_methods, figsize=(5 * n_methods, 5))\n",
    "\n",
    "# Loop through and plot\n",
    "for ax, (title, conf) in zip(axes, methods.items()):\n",
    "    X_embedded = conf[\"func\"](X_hvg)\n",
    "\n",
    "    sns.scatterplot(\n",
    "        x=X_embedded[:, 0],\n",
    "        y=X_embedded[:, 1],\n",
    "        hue=rna_family,  # rna_type,  # color by cell type\n",
    "        # c=ephys_df[\"AP width (ms)\"],  [\"Max number of APs\"] [\"AP amplitude (mV)\"] [\"Latency (ms)\"]\n",
    "        # cmap=\"inferno\",  # change colormap here\n",
    "        palette=\"tab10\",\n",
    "        # c=rna_type_colors,\n",
    "        s=30,\n",
    "        alpha=0.7,\n",
    "        legend=False,\n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Dim 1\")\n",
    "    ax.set_ylabel(\"Dim 2\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation across visualization types: \n",
    "\n",
    "PCA\n",
    "\n",
    "* no clear clusters.\n",
    "* seems to capture global variance, but fails to separate subtle biological subpopulations\n",
    "=> rather use for noise reduction / preprocessing\n",
    "\n",
    "t-SNE (`n_neighbors`=30)\n",
    "\n",
    "* multiple well-separated clusters.\n",
    "* seems to reveal local structure, separating even small subpopulations\n",
    "* downside: t-SNE is not ideal for preserving global relationships\n",
    "\n",
    "UMAP (`n_neighbors`=15)\n",
    "\n",
    "* distinct clusters, some continuity\n",
    "* seems to balances local and global structure, showing gradients and groupings\n",
    "\n",
    "\n",
    "=> further proceedings:\n",
    "\n",
    "* Use PCA as input to UMAP/t-SNE\n",
    "* Use UMAP or t-SNE for cluster discovery or cell type visualization.\n",
    "\n",
    "\n",
    "TODO:we can try coloring by RNA type, cluster ID, or marker expression to aid interpretation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Comparison using Quantitative Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import recall_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import umap\n",
    "from sklearn.metrics import silhouette_score, adjusted_mutual_info_score\n",
    "\n",
    "\"\"\" def safe_tsne_10d(X, name=\"t-SNE\"):\n",
    "    if X.shape[0] < 50 or X.shape[1] < 10:\n",
    "        raise ValueError(f\"{name}: Too few samples or features for 10D t-SNE\")\n",
    "    return TSNE(n_components=10, perplexity=30, random_state=42).fit_transform(\n",
    "        X\n",
    "    ) \"\"\"\n",
    "\n",
    "\n",
    "def evaluate_knn_projection(\n",
    "    log_cpm_df,\n",
    "    hvg_genes,\n",
    "    labels,\n",
    "    n_neighbors=10,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    pca_components_for_tsne_umap=50,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compare dimensionality reduction methods using kNN classification metrics.\n",
    "\n",
    "    Parameters:\n",
    "        log_cpm_df (DataFrame): log(CPM)-normalized gene expression (cells × genes)\n",
    "        hvg_genes (list): list of highly variable gene names\n",
    "        labels (array-like): class labels for each cell (e.g., RNA type)\n",
    "        n_neighbors (int): number of neighbors for kNN\n",
    "        test_size (float): train/test split size\n",
    "        random_state (int): reproducibility seed\n",
    "        pca_components_for_tsne_umap (int): number of PCs to feed into t-SNE/UMAP\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with accuracy and recall for each method.\n",
    "    \"\"\"\n",
    "    # Standardize input data\n",
    "    X_hvg = StandardScaler().fit_transform(log_cpm_df[hvg_genes].values)\n",
    "    # X_hvg =X_hvg_filtered\n",
    "    y = np.array(labels)\n",
    "\n",
    "    # Precompute PCA-reduced input for non-linear methods\n",
    "    X_pca_for_embedding = PCA(\n",
    "        n_components=pca_components_for_tsne_umap\n",
    "    ).fit_transform(X_hvg)\n",
    "\n",
    "    # print(\"X shape:\", X.shape)\n",
    "    # print(\"X_pca_for_embedding shape:\", X_pca_for_embedding.shape)\n",
    "\n",
    "    methods = {\n",
    "        \"High-dimensional (raw)\": lambda X: X,\n",
    "        \"PCA (2D)\": lambda X: PCA(n_components=2).fit_transform(X),\n",
    "        \"PCA (10D)\": lambda X: PCA(n_components=10).fit_transform(X),\n",
    "        \"PCA (25D)\": lambda X: PCA(n_components=25).fit_transform(X),\n",
    "        \"t-SNE (2D)\": lambda X: TSNE(\n",
    "            n_components=2, perplexity=30, random_state=random_state\n",
    "        ).fit_transform(X),\n",
    "        \"t-SNE (2D from PCA)\": lambda _: TSNE(\n",
    "            n_components=2, perplexity=30, random_state=random_state\n",
    "        ).fit_transform(X_pca_for_embedding),\n",
    "        \"t-SNE (10D)\": lambda X: TSNE(\n",
    "            n_components=10,\n",
    "            perplexity=30,\n",
    "            method=\"exact\",\n",
    "            random_state=random_state,\n",
    "        ).fit_transform(X),\n",
    "        \"t-SNE (10D from PCA)\": lambda _: TSNE(\n",
    "            n_components=10,\n",
    "            perplexity=30,\n",
    "            method=\"exact\",\n",
    "            random_state=random_state,\n",
    "        ).fit_transform(X_pca_for_embedding),\n",
    "        \"UMAP (2D)\": lambda X: umap.UMAP(\n",
    "            n_neighbors=15, min_dist=0.1, random_state=random_state\n",
    "        ).fit_transform(X),\n",
    "        \"UMAP (2D from PCA)\": lambda _: umap.UMAP(\n",
    "            n_neighbors=15, min_dist=0.1, random_state=random_state\n",
    "        ).fit_transform(X_pca_for_embedding),\n",
    "        \"UMAP (10D from PCA)\": lambda _: umap.UMAP(\n",
    "            n_neighbors=15,\n",
    "            min_dist=0.1,\n",
    "            n_components=10,\n",
    "            random_state=random_state,\n",
    "        ).fit_transform(X_pca_for_embedding),\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "    for name, func in methods.items():\n",
    "        try:\n",
    "            X_proj = func(X_hvg)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X_proj,\n",
    "                y,\n",
    "                test_size=test_size,\n",
    "                random_state=random_state,\n",
    "            )\n",
    "            print(f\"{name}: X_proj shape = {X_proj.shape}\")\n",
    "\n",
    "            clf = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "            clf.fit(X_train, y_train)\n",
    "            acc = clf.score(X_test, y_test)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            avg_recall = recall_score(\n",
    "                y_test, y_pred, average=\"macro\", zero_division=0\n",
    "            )\n",
    "\n",
    "            # compute silhouette score and AMI as in Lause, Berens, Kobak (2024):\n",
    "\n",
    "            # silhouette score\n",
    "            sil = silhouette_score(X_proj, y)\n",
    "            # unsupervised clustering for AMI\n",
    "            n_clusters = len(np.unique(y))\n",
    "            cluster_labels = KMeans(\n",
    "                n_clusters=n_clusters, random_state=random_state\n",
    "            ).fit_predict(X_proj)\n",
    "            ami = adjusted_mutual_info_score(y, cluster_labels)\n",
    "\n",
    "            results.append(\n",
    "                {\n",
    "                    \"Method\": name,\n",
    "                    \"kNN Accuracy\": acc,\n",
    "                    \"kNN Recall (avg)\": avg_recall,\n",
    "                    \"Silhouette Score\": sil,\n",
    "                    \"AMI\": ami,\n",
    "                }\n",
    "            )\n",
    "        except Exception as e:\n",
    "            results.append(\n",
    "                {\n",
    "                    \"Method\": name,\n",
    "                    \"kNN Accuracy\": None,\n",
    "                    \"kNN Recall (avg)\": None,\n",
    "                    \"Silhouette Score\": None,\n",
    "                    \"AMI\": None,\n",
    "                    \"Error\": str(e),\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df = evaluate_knn_projection(log_cpm_df, hvg_genes, rna_type)\n",
    "results_df = evaluate_knn_projection(\n",
    "    log_cpm_df=log_cpm_df,\n",
    "    hvg_genes=hvg_genes,\n",
    "    labels=rna_type,\n",
    "    n_neighbors=10,\n",
    "    pca_components_for_tsne_umap=50,\n",
    ")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Overall (based on all metrics): t-SNE (10D from PCA):\n",
    "* kNN Accuracy: 0.46\n",
    "* Recall: 0.26\n",
    "* AMI: 0.44 (highest)\n",
    "* Silhouette: ~-0.21\n",
    "\n",
    "kNN-performance of the models:\n",
    "* t-SNE (10D) is our best performer in terms of accuracy\n",
    "* t-SNE (10D from PCA) has the highest recall\n",
    "* PCA (2D) performs poorly — linear reduction to 2D just doesn't work well for this data.\n",
    "* UMAP is competitive but doesn't benefit much from going to 10D\n",
    "* Raw high-dimensional data still performs surprisingly well — showing that your data has strong native structure.\n",
    "* a kNN accuracy of ~0.42 is not high but seems acceptable given the biological data\n",
    "\n",
    "Overall low silhouette scores:\n",
    "All low-dimensional methods have negative silhouette scores, meaning clusters may be overlapping or poorly separated.\n",
    "This is common in t-SNE/UMAP, as they optimize local structure rather than global clustering.\n",
    "\n",
    "AMI scores:\n",
    "Most AMI scores surpass 0.4, which indicates moderately good label-cluster alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots kNN accuracy vs. recall for different dimensionality reduction methods\n",
    "### N: weiß nich ob wir brauchen/wollen?\n",
    "\n",
    "# from adjustText import adjust_text\n",
    "\n",
    "\n",
    "def plot_knn_accuracy_vs_recall(results_df, figsize=(8, 6)):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        results_df (DataFrame): must contain columns 'Method', 'kNN Accuracy', and 'kNN Recall (avg)'\n",
    "        figsize (tuple): size of the plot (width, height)\n",
    "    \"\"\"\n",
    "    methods = results_df[\"Method\"]\n",
    "    accuracy = results_df[\"kNN Accuracy\"]\n",
    "    recall = results_df[\"kNN Recall (avg)\"]\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    texts = []\n",
    "\n",
    "    # plot points\n",
    "    for i in range(len(methods)):\n",
    "        plt.scatter(accuracy[i], recall[i], s=200, label=methods[i])\n",
    "        plt.text(accuracy[i], recall[i], methods[i], fontsize=8, rotation=15)\n",
    "\n",
    "    plt.xlabel(\"kNN Accuracy\")\n",
    "    plt.ylabel(\"kNN Recall (macro avg)\")\n",
    "    plt.title(\"kNN Accuracy vs. Recall for Dimensionality Reduction Methods\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_knn_accuracy_vs_recall(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!! umformulieren\n",
    "\n",
    "\n",
    "* t-SNE (2D) nearly matches the accuracy of the high-dimensional data while even slightly improving average recall — showing it's preserving neighborhood structure quite well in 2D.\n",
    "* UMAP (2D) performs reasonably, a bit behind t-SNE, but still far ahead of PCA.\n",
    "* PCA (2D) performs poorly — this confirms PCA doesn't capture non-linear relationships or local structure well in low dimensions.\n",
    "* High-dimensional kNN is strongest overall (as expected), but not dramatically better than t-SNE — suggesting your 2D t-SNE visualizations are biologically meaningful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using electrophysiological features and other metadata to enhance different visualizations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define 2D projections\n",
    "X_pca2 = PCA(n_components=2).fit_transform(X_hvg)\n",
    "X_tsne2 = TSNE(\n",
    "    n_components=2, perplexity=30, method=\"exact\", random_state=42\n",
    ").fit_transform(X_hvg)\n",
    "X_umap2 = umap.UMAP(\n",
    "    n_components=2, n_neighbors=15, min_dist=0.1, random_state=42\n",
    ").fit_transform(X_hvg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot models from above\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "titles = [\"PCA (2D)\", \"t-SNE (2D)\", \"UMAP (2D)\"]\n",
    "embeddings = [X_pca25_2d, X_tsne10_2d, X_umap10_2d]\n",
    "\n",
    "for ax, title, embed in zip(axes, titles, embeddings):\n",
    "    sns.scatterplot(\n",
    "        x=embed[:, 0],\n",
    "        y=embed[:, 1],\n",
    "        hue=rna_family,  # rna_type,  # or rna_type\n",
    "        palette=\"tab10\",\n",
    "        s=30,\n",
    "        alpha=0.8,\n",
    "        legend=False,\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Dim 1\")\n",
    "    ax.set_ylabel(\"Dim 2\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 prepare data\n",
    "\n",
    "* transcriptomics data is already normalized, hvgs were selected, PCA applied\n",
    "* electrophysiological data: standardize/normalize (z-score), maybe apply PCA\n",
    "\n",
    "then:\n",
    "* match cells across modalities (=align them via cell IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(meta[[\"Cell\", \"RNA type\"]].head())\n",
    "print(meta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(log_cpm_df.shape, ephys_df.shape, meta.shape)\n",
    "print(log_cpm_df.index[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the existing index of log_cpm_df as the reference\n",
    "cell_ids = log_cpm_df.index\n",
    "\n",
    "# Subset meta and ephys_df to only those cells\n",
    "meta_subset = meta.loc[meta.index.isin(cell_ids)].copy()\n",
    "ephys_subset = ephys_df.loc[ephys_df.index.isin(cell_ids)].copy()\n",
    "\n",
    "# Now align everything to the same cell ID index\n",
    "meta_subset.index = cell_ids\n",
    "ephys_subset.index = cell_ids\n",
    "log_cpm_df = log_cpm_df.loc[cell_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(log_cpm_df.shape, ephys_subset.shape, meta_subset.shape)\n",
    "print(log_cpm_df.index[:5])  # Should show matching cell IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize gene expression data\n",
    "X_hvg = StandardScaler().fit_transform(log_cpm_df[hvg_genes])\n",
    "\n",
    "# Run PCA\n",
    "pca = PCA(n_components=25)  # choose number of PCs to keep\n",
    "X_pca = pca.fit_transform(X_hvg)\n",
    "\n",
    "# Convert to DataFrame for easier correlation\n",
    "pca_df = pd.DataFrame(\n",
    "    X_pca,\n",
    "    columns=[f\"PC{i+1}\" for i in range(X_pca.shape[1])],\n",
    "    index=log_cpm_df.index,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 explore relationships\n",
    "\n",
    "* correlation analysis\n",
    "* regression models\n",
    "\n",
    "**canonical correlation analysis**\n",
    "\n",
    "* Identify pairs of latent dimensions that co-vary across RNA and e-phys.\n",
    "* Seurat and Scanpy can run CCA.\n",
    "\n",
    "**clustering / dimensionality reduction**\n",
    "* Jointly embed both modalities (e.g., MOFA+, MultiVI, or Concatenated PCA).\n",
    "* Then cluster cells and see if these clusters correspond to known cell types or exhibit interesting features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1 correlation analysis\n",
    "\n",
    "* compute correlations between electrophysiological features and PCA components\n",
    "* compute correlations between electrophysiological features and genes\n",
    "* => visualize top hits using heatmaps or scatter plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for all features vs all PCs:\n",
    "cor_matrix_full = pd.DataFrame(\n",
    "    index=ephys_subset.columns, columns=pca_df.columns\n",
    ")\n",
    "for ef in ephys_df.columns:\n",
    "    for pc in pca_df.columns:\n",
    "        cor_matrix_full.loc[ef, pc] = ephys_subset[ef].corr(pca_df[pc])\n",
    "cor_matrix_full = cor_matrix_full.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(\n",
    "    cor_matrix_full, annot=True, cmap=\"vlag\", center=0, annot_kws={\"size\": 7}\n",
    ")\n",
    "plt.title(\n",
    "    \"Correlation between electrophysiological features and PCA components\"\n",
    ")\n",
    "plt.xlabel(\"Principal Components\")\n",
    "plt.ylabel(\"Ephys Features\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all column names to uppercase to standardize for matching\n",
    "log_cpm_df.columns = log_cpm_df.columns.str.upper()\n",
    "\n",
    "# Define ion channel gene families of interest\n",
    "ion_channel_prefixes = [\"KCNK\", \"SCN\", \"HCN\"]\n",
    "\n",
    "# Select genes that contain any of the ion channel prefixes\n",
    "ion_genes = [\n",
    "    gene\n",
    "    for gene in log_cpm_df.columns\n",
    "    if any(prefix in gene for prefix in ion_channel_prefixes)\n",
    "]\n",
    "\n",
    "# Subset expression matrix to only those genes\n",
    "ion_expr = log_cpm_df[ion_genes]\n",
    "\n",
    "print(f\"Found {len(ion_genes)} ion channel genes in log_cpm_df.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure index alignment is correct\n",
    "common_cells = ion_expr.index.intersection(ephys_df.index)\n",
    "ion_expr = ion_expr.loc[common_cells]\n",
    "ephys_subset = ephys_df.loc[common_cells][\n",
    "    [\"AP threshold (mV)\", \"Rheobase (pA)\", \"Membrane time constant (ms)\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlation matrix between genes and selected ephys features\n",
    "cor_matrix = ion_expr.corrwith(\n",
    "    ephys_subset[\"AP threshold (mV)\"], axis=0\n",
    ").to_frame(name=\"AP threshold\")\n",
    "cor_matrix[\"Rheobase\"] = ion_expr.corrwith(\n",
    "    ephys_subset[\"Rheobase (pA)\"], axis=0\n",
    ")\n",
    "cor_matrix[\"Membrane time constant\"] = ion_expr.corrwith(\n",
    "    ephys_subset[\"Membrane time constant (ms)\"], axis=0\n",
    ")\n",
    "\n",
    "# Transpose to make it easier to read\n",
    "cor_matrix = cor_matrix.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(cor_matrix, annot=True, cmap=\"vlag\", center=0, fmt=\".2f\")\n",
    "plt.title(\"Correlation between Ion Channel Gene Expression and Ephys Features\")\n",
    "plt.xlabel(\"Ion Channel Genes\")\n",
    "plt.ylabel(\"Ephys Features\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Interpretation*\n",
    "\n",
    "TODO: BISSLE UMFORMULIEREN\n",
    "\n",
    "* Rheobase has the most pronounced correlations (up to ~0.13), suggesting some ion channel genes might influence current threshold.\n",
    "* KCNK family genes (potassium channels) appear to correlate modestly with membrane time constant and AP threshold, as expected due to their role in setting resting potential and excitability.\n",
    "* Some SCN genes (sodium channels) also show modest correlations, especially with AP threshold and Rheobase, which is consistent with their role in spike initiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ephys_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot scatter plots for strongest gene-feature pairs\n",
    "\n",
    "# identify strongest correlations\n",
    "cor_df = cor_matrix.stack().reset_index()\n",
    "cor_df.columns = [\"Ephys Feature\", \"Gene\", \"Pearson r\"]\n",
    "cor_df[\"abs_r\"] = cor_df[\"Pearson r\"].abs()\n",
    "top_corrs = cor_df.sort_values(\"abs_r\", ascending=False).head(6)\n",
    "\n",
    "# plot scatterplots for top gerne-feature pairs\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (_, row) in enumerate(top_corrs.iterrows()):\n",
    "    ephys_feature = row[\"Ephys Feature\"]\n",
    "    gene = row[\"Gene\"]\n",
    "    r_val = row[\"Pearson r\"]\n",
    "\n",
    "    # extract data\n",
    "    x = log_cpm_df[gene]\n",
    "    y = ephys_df[ephys_feature]\n",
    "\n",
    "    # scatter plot with regression line\n",
    "    sns.scatterplot(x=x, y=y, ax=axes[i], alpha=0.6, edgecolor=None)\n",
    "    sns.regplot(x=x, y=y, ax=axes[i], scatter=False, color=\"red\", ci=None)\n",
    "\n",
    "    axes[i].set_title(f\"{gene} vs. {ephys_feature}\\nPearson r = {r_val:.2f}\")\n",
    "    axes[i].set_xlabel(f\"{gene} expression (log CPM)\")\n",
    "    axes[i].set_ylabel(ephys_feature)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Top 6 Correlated Gene-Feature Pairs\", fontsize=16, y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at statistical significance of correlations\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Select genes of interest\n",
    "ion_channel_genes = [\n",
    "    \"OBSCN\",\n",
    "    \"SCN4B\",\n",
    "    \"SCN8A\",\n",
    "]  # list of genes => which ones do we want to look at??\n",
    "\n",
    "# Subset gene expression\n",
    "X_genes = log_cpm_df[ion_channel_genes].loc[ephys_df.index]\n",
    "\n",
    "# Subset ephys features\n",
    "ephys_features = [\n",
    "    \"AP threshold (mV)\",\n",
    "    \"Rheobase (pA)\",\n",
    "    \"Membrane time constant (ms)\",\n",
    "]\n",
    "X_ephys = ephys_df[ephys_features]\n",
    "\n",
    "# Initialize results\n",
    "cor_matrix = pd.DataFrame(index=ephys_features, columns=ion_channel_genes)\n",
    "pval_matrix = pd.DataFrame(index=ephys_features, columns=ion_channel_genes)\n",
    "\n",
    "# Compute correlations and p-values\n",
    "for feature in ephys_features:\n",
    "    for gene in ion_channel_genes:\n",
    "        corr, pval = pearsonr(X_genes[gene], X_ephys[feature])\n",
    "        cor_matrix.at[feature, gene] = corr\n",
    "        pval_matrix.at[feature, gene] = pval\n",
    "\n",
    "# Optionally, mask non-significant values\n",
    "significance_mask = pval_matrix.astype(float) < 0.05\n",
    "annot_matrix = cor_matrix.round(2).astype(str)\n",
    "annot_matrix[~significance_mask] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap to visualize significance\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.heatmap(\n",
    "    cor_matrix.astype(float),\n",
    "    annot=annot_matrix,\n",
    "    fmt=\"s\",\n",
    "    cmap=\"vlag\",\n",
    "    center=0,\n",
    "    cbar_kws={\"label\": \"Pearson r\"},\n",
    ")\n",
    "plt.title(\n",
    "    \"Ion Channel Gene Expression vs Ephys Features (Significant Correlations Annotated)\"\n",
    ")\n",
    "plt.xlabel(\"Ion Channel Genes\")\n",
    "plt.ylabel(\"Ephys Features\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SCN8A shows a positive correlation (~0.13) with Rheobase, which may suggest that higher expression of SCN8A (a voltage-gated sodium channel gene) is associated with increased current required to elicit an action potential.\n",
    "\n",
    "OBSCN expression correlates positively with membrane time constant, so structural genes might be linked to passive membrane properties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2 regression models\n",
    "\n",
    "Predict e-phys features from transcriptomic data:\n",
    "\n",
    "* Use linear regression, random forests, or elastic net on PCA-reduced gene expression.\n",
    "* Evaluate using cross-validation (R², RMSE).\n",
    "\n",
    "Partial Least Squares Regression (PLSR) is popular for this kind of analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import pandas as pd\n",
    "\n",
    "# Reuse PCA features (assumes X_pca and pca_df already exist)\n",
    "# X = X_pca\n",
    "# Recompute HVGs from the current log_cpm_df\n",
    "gene_variances = log_cpm_df.var().sort_values(ascending=False)\n",
    "hvg_genes = gene_variances.head(2000).index.tolist()\n",
    "\n",
    "top_n = 100\n",
    "hvg_subset = hvg_genes[:top_n]\n",
    "X_hvg = StandardScaler().fit_transform(log_cpm_df[hvg_subset])\n",
    "\n",
    "X = X_hvg  # X_pca\n",
    "ephys_targets = [\n",
    "    \"AP threshold (mV)\",\n",
    "    \"Rheobase (pA)\",\n",
    "    \"Membrane time constant (ms)\",\n",
    "]\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"Elastic Net\": ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=42),\n",
    "}\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "# Loop through each ephys feature\n",
    "for feature in ephys_targets:\n",
    "    y = ephys_df[feature].values\n",
    "\n",
    "    for name, model in models.items():\n",
    "        pipe = make_pipeline(StandardScaler(), model)\n",
    "        scores = cross_validate(\n",
    "            pipe, X, y, cv=5, scoring=[\"r2\", \"neg_root_mean_squared_error\"]\n",
    "        )\n",
    "        results.append(\n",
    "            {\n",
    "                \"Model\": name,\n",
    "                \"Ephys Feature\": feature,\n",
    "                \"Mean R2\": scores[\"test_r2\"].mean(),\n",
    "                \"Mean RMSE\": -scores[\n",
    "                    \"test_neg_root_mean_squared_error\"\n",
    "                ].mean(),\n",
    "            }\n",
    "        )\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> very poor performance at the moment :/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Biological Interpretability\n",
    "\n",
    "Identify genes most correlated with electrophysiological properties.\n",
    "Perform gene ontology (GO) enrichment or pathway analysis on these genes.\n",
    "Validate known relationships: e.g., do cells with fast APs express SCN1A highly?\n",
    "Explore novel marker relationships for specific firing behaviors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "Lause, J., Berens, P., & Kobak, D. (2024). The art of seeing the elephant in the room: 2D embeddings of single-cell data do make sense. *PLoS Computational Biology*, 20(10), e1012403. https://doi.org/10.1371/journal.pcbi.1012403"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
