{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Neural Data Science_\n",
    "\n",
    "Lecturer: Dr. Jan Lause, Prof. Dr. Philipp Berens\n",
    "\n",
    "Tutors: Jonas Beck, Fabio Seel, Julius Würzler\n",
    "\n",
    "Summer term 2025\n",
    "\n",
    "Student names: Nina Lutz, Mathis Nommensen\n",
    "\n",
    "LLM Disclaimer: <span style='background: yellow'>*Did you use an LLM to solve this exercise? If yes, which one and where did you use it? [Copilot, Claude, ChatGPT, etc.]* </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Single-cell data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install memory-profiler #N: i needed to install this. delete code block if not needed anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook #N: had to change this\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import string\n",
    "\n",
    "import scipy as sp\n",
    "from scipy import sparse\n",
    "import sklearn\n",
    "\n",
    "## add your packages ##\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "import memory_profiler\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "\n",
    "%load_ext memory_profiler\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import black\n",
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load(line_length=79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_path = Path(\"../results/variables\")\n",
    "figures_path = Path(\"../results/figures\")\n",
    "data_path = Path(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.style.use(\"matplotlib_style.txt\")\n",
    "plt.style.use(\"../matplotlib_style.txt\")  # N: had to change this as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project and data description\n",
    "\n",
    "In this project, we are going to work with the typical methods and pipelines used in single-cell data analysis and get some hands-on experience with the techniques used in the field. For that, we will be using Patch-seq multimodal data from cortical neurons in mice, from Scala et al. 2021 (https://www.nature.com/articles/s41586-020-2907-3#Sec7). From the different data modalities they used, we will focus on transcriptomics and electrophysiological data. \n",
    "\n",
    "In a real-world scenario, single cell data rarely comes with any \"ground truth\" labels. Often, the goal of researchers after measuring cells is to precisely classify them, grouping them into families or assigning them cell types based on the recorded features. This is normally done using usupervised methods, such as clustering methods.\n",
    "\n",
    "However, the single-cell data that we are using in this project has some cell types assigned to each cell. These are not \"ground truth\" type annotations, but were one of the results from the original Scala et al. work. Still, we are going to use those annotations for validation (despite them not really being ground truth) to sanity-check some of our analyses, such as visualizations, clustering, etc. We will mainly work with cell types (`rna_types`, 77 unique types) and cell families (`rna_families`, 9 unique families).\n",
    "\n",
    "From the transcriptomics mRNA counts, we will only work with the exon counts for simplicity. Some of the electrophysiological features are not high-quality recordings, therefore we will also filter them out."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# META DATA\n",
    "\n",
    "meta = pd.read_csv(data_path / \"m1_patchseq_meta_data.csv\", sep=\"\\t\")\n",
    "\n",
    "cells = meta[\"Cell\"].values\n",
    "\n",
    "layers = meta[\"Targeted layer\"].values.astype(\"str\")\n",
    "cre = meta[\"Cre\"].values\n",
    "yields = meta[\"Yield (pg/µl)\"].values\n",
    "yields[yields == \"?\"] = np.nan\n",
    "yields = yields.astype(\"float\")\n",
    "depth = meta[\"Soma depth (µm)\"].values\n",
    "depth[depth == \"Slice Lost\"] = np.nan\n",
    "depth = depth.astype(float)\n",
    "thickness = meta[\"Cortical thickness (µm)\"].values\n",
    "thickness[thickness == 0] = np.nan\n",
    "thickness = thickness.astype(float)\n",
    "traced = meta[\"Traced\"].values == \"y\"\n",
    "exclude = meta[\"Exclusion reasons\"].values.astype(str)\n",
    "exclude[exclude == \"nan\"] = \"\"\n",
    "\n",
    "mice_names = meta[\"Mouse\"].values\n",
    "mice_ages = meta[\"Mouse age\"].values\n",
    "mice_cres = np.array(\n",
    "    [\n",
    "        c if c[-1] != \"+\" and c[-1] != \"-\" else c[:-1]\n",
    "        for c in meta[\"Cre\"].values\n",
    "    ]\n",
    ")\n",
    "mice_ages = dict(zip(mice_names, mice_ages))\n",
    "mice_cres = dict(zip(mice_names, mice_cres))\n",
    "\n",
    "print(\"Number of cells with measured depth:    \", np.sum(~np.isnan(depth)))\n",
    "print(\"Number of cells with measured thickness:\", np.sum(~np.isnan(thickness)))\n",
    "print(\"Number of reconstructed cells:          \", np.sum(traced))\n",
    "\n",
    "sliceids = meta[\"Slice\"].values\n",
    "a, b = np.unique(sliceids, return_counts=True)\n",
    "assert np.all(b <= 2)\n",
    "print(\"Number of slices with two cells:        \", np.sum(b == 2))\n",
    "\n",
    "# Some consistency checks\n",
    "assert np.all(\n",
    "    [\n",
    "        np.unique(meta[\"Date\"].values[mice_names == m]).size == 1\n",
    "        for m in mice_names\n",
    "    ]\n",
    ")\n",
    "assert np.all(\n",
    "    [\n",
    "        np.unique(meta[\"Mouse age\"].values[mice_names == m]).size == 1\n",
    "        for m in mice_names\n",
    "    ]\n",
    ")\n",
    "assert np.all(\n",
    "    [\n",
    "        np.unique(meta[\"Mouse gender\"].values[mice_names == m]).size == 1\n",
    "        for m in mice_names\n",
    "    ]\n",
    ")\n",
    "assert np.all(\n",
    "    [\n",
    "        np.unique(meta[\"Mouse genotype\"].values[mice_names == m]).size == 1\n",
    "        for m in mice_names\n",
    "    ]\n",
    ")\n",
    "assert np.all(\n",
    "    [\n",
    "        np.unique(meta[\"Mouse\"].values[sliceids == s]).size == 1\n",
    "        for s in sliceids\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Ground truth labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out low quality cells in term of RNA\n",
    "print(\n",
    "    \"There are\",\n",
    "    np.sum(meta[\"RNA family\"] == \"low quality\"),\n",
    "    \"cells with low quality RNA recordings.\",\n",
    ")\n",
    "exclude_low_quality = meta[\"RNA family\"] != \"low quality\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rna_family = meta[\"RNA family\"][exclude_low_quality]\n",
    "rna_type = meta[\"RNA type\"][exclude_low_quality]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(np.unique(rna_family)))\n",
    "print(len(np.unique(rna_type)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(data_path / \"dict_rna_type_colors.pkl\", \"rb\")\n",
    "dict_rna_type_colors = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rna_type_colors = np.vectorize(dict_rna_type_colors.get)(rna_type)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcriptomic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ COUNTS\n",
    "data_exons = pd.read_csv(\n",
    "    data_path / \"m1_patchseq_exon_counts.csv.gz\", na_filter=False, index_col=0\n",
    ")\n",
    "\n",
    "assert all(cells == data_exons.columns)\n",
    "genes = np.array(data_exons.index)\n",
    "\n",
    "# filter out low quality cells in term of rna family\n",
    "exonCounts = data_exons.values.transpose()[exclude_low_quality]\n",
    "print(\"Count matrix shape (exon):  \", exonCounts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENE LENGTH\n",
    "\n",
    "data = pd.read_csv(data_path / \"gene_lengths.txt\")\n",
    "assert all(data[\"GeneID\"] == genes)\n",
    "exonLengths = data[\"exon_bp\"].values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Electrophysiological features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPHYS DATA\n",
    "\n",
    "ephysData = pd.read_csv(data_path / \"m1_patchseq_ephys_features.csv\")\n",
    "ephysNames = np.array(ephysData.columns[1:]).astype(str)\n",
    "ephysCells = ephysData[\"cell id\"].values\n",
    "ephysData = ephysData.values[:, 1:].astype(\"float\")\n",
    "names2ephys = dict(zip(ephysCells, ephysData))\n",
    "ephysData = np.array(\n",
    "    [\n",
    "        names2ephys[c] if c in names2ephys else ephysData[0] * np.nan\n",
    "        for c in cells\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Number of cells with ephys data:\", np.sum(np.isin(cells, ephysCells)))\n",
    "\n",
    "assert np.sum(~np.isin(ephysCells, cells)) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering ephys data\n",
    "\n",
    "features_exclude = [\n",
    "    \"Afterdepolarization (mV)\",\n",
    "    \"AP Fano factor\",\n",
    "    \"ISI Fano factor\",\n",
    "    \"Latency @ +20pA current (ms)\",\n",
    "    \"Wildness\",\n",
    "    \"Spike frequency adaptation\",\n",
    "    \"Sag area (mV*s)\",\n",
    "    \"Sag time (s)\",\n",
    "    \"Burstiness\",\n",
    "    \"AP amplitude average adaptation index\",\n",
    "    \"ISI average adaptation index\",\n",
    "    \"Rebound number of APs\",\n",
    "]\n",
    "features_log = [\n",
    "    \"AP coefficient of variation\",\n",
    "    \"ISI coefficient of variation\",\n",
    "    \"ISI adaptation index\",\n",
    "    \"Latency (ms)\",\n",
    "]\n",
    "\n",
    "X = ephysData[exclude_low_quality]\n",
    "print(X.shape)\n",
    "for e in features_log:\n",
    "    X[:, ephysNames == e] = np.log(X[:, ephysNames == e])\n",
    "X = X[:, ~np.isin(ephysNames, features_exclude)]\n",
    "\n",
    "keepcells = ~np.isnan(np.sum(X, axis=1))\n",
    "X = X[keepcells, :]\n",
    "print(X.shape)\n",
    "\n",
    "X = X - X.mean(axis=0)\n",
    "ephysData_filtered = X / X.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.isnan(ephysData_filtered))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research questions to investigate\n",
    "\n",
    "**1) Inspect the data by computing key statistics.** For RNA counts, you can compute and plot statistics, e.g. total counts per cell, number of expressed genes per cell, mean count per gene, variance per gene, mean-variance relationship... See https://www.embopress.org/doi/full/10.15252/msb.20188746 for common quality control statistics. Keep in mind that the RNA data in this project is read counts, not UMI counts, so it is not supposed to follow a Poisson distribution. To get an idea of the technical noise in the data, you can plot count distributions of single genes within cell types (like in the lecture). \n",
    "\n",
    "Similarly, you can compute and plot statistics over the electrophyiological data. Also, investigate the distribution of \"ground truth\" labels. Comment about other relevant metadata, and think if you can use it as some external validation for other analyses. If you do use other metadata throughout the project, explain why and what you get out of it. Take into account that certain features may not be very informative for our purposes (e.g. mouse age), so only choose features that provide you with useful information in this context. If you want to get additional information about the metadata, have a look at the extended data section in the original publication (e.g., cre-lines in Figure 1c in the extended data).\n",
    "\n",
    "**2) Normalize & transform the data; select genes & apply PCA.** There are several ways of normalizing the RNA count data (Raw, CPM, CPMedian, RPKM, see https://www.reneshbedre.com/blog/expression_units.html, https://translational-medicine.biomedcentral.com/articles/10.1186/s12967-021-02936-w). Take into account that there are certain normalizations that only make sense for UMI data, but not for this read count data. You also explored different transformations in the assignment (none, log, sqrt). Compare how the different transformations change the two-dimensional visualization. After normalization and transformation, choose a set of highly variable genes (as demonstrated in the lecture) and apply PCA. Play with the number of selected genes and the number of PCA components, and again compare their effects on the two-dimensional visualization.\n",
    "\n",
    "**3) Two-dimensional visualization.** To visualize the RNA count data after normalization, transformation, gene selection and PCA, try different methods (just PCA, t-SNE, UMAP, ..) and vary their parameters (exaggeration, perplexity, ..). Compare them using quantitative metrics (e.g., kNN accuracy in high-dim vs. two-dim, kNN recall). Please refer to Lause et al., 2024 (https://doi.org/10.1371/journal.pcbi.1012403) where many of these metrics are discussed and explained to make an informed choice on which metrics to use. Think about also using the electrophysiological features and other metadata to enhance different visualizations.\n",
    "\n",
    "**4) Clustering.** To find cell types in the RNA count data, you will need to look for clusters. Try different clustering methods (leiden, GMM). Implement a negative binomial mixture model. For that you can follow a similar method that what is described in Harris et al. 2018 (https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.2006387#abstract0), with fixed r (r=2). Feel free to simplify the setup from the paper and not optimize over the set of important genes S but fix it instead, or skip the split and merge part of their clustering algorithm. A vanilla NBMM implementation should suffice. Take into account that the NBMM tries to cluster data that follows a negative binomial distribution. Therefore, it does not make sense to apply this clustering method to all kinds of normalized and transformed data. Please refer to the Harris et al. 2018 publication for the appropriate choice of normalization, and reflect on why this normalization makes sense. Evaluate your clustering results (metrics, compare number of clusters to original labels,...).\n",
    "\n",
    "**5) Correlation between electrophysiological features and genes/PCs.** Finally, connect RNA counts and functional data: Most likely, there will be interesting relationships between the transcriptomic and electrophyiological features in this data. Find these correlations and a way of visualizing them. In studying correlations using the PCA-reduced version of the transcriptomics data, it could be interesting to study PC loadings to see which genes are dominating which PCs. For other advanced analyses, you can get inspitation from Kobak et al., 2021 (https://doi.org/10.1111/rssc.12494).\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "\n",
    "**1.1 QC Statistics per cell.**\n",
    "\n",
    "RNA Counts and stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exonCounts.shape[0]\n",
    "exonCounts.shape[1]\n",
    "exonCounts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total counts per cell (count depth)\n",
    "\n",
    "# exonCounts  # shape = 1232 cells x 42466 genes\n",
    "total_counts_per_cell = total_counts_per_cell = exonCounts.sum(axis=1)\n",
    "\n",
    "# plot\n",
    "fig, axes = plt.subplots(1, 3, figsize=(10, 4))\n",
    "\n",
    "axes[0].hist(\n",
    "    total_counts_per_cell, bins=50, color=\"skyblue\", edgecolor=\"black\"\n",
    ")\n",
    "axes[0].set_xlabel(\"Total RNA counts per cell\")\n",
    "axes[0].set_ylabel(\"Number of cells\")\n",
    "axes[0].set_title(\"Distribution of Total Counts Per Cell\")\n",
    "\n",
    "axes[1].scatter(\n",
    "    range(len(total_counts_per_cell)), total_counts_per_cell, s=5, alpha=0.5\n",
    ")\n",
    "axes[1].set_yscale(\"log\")\n",
    "axes[1].set_xlabel(\"Cell index\")\n",
    "axes[1].set_ylabel(\"Total RNA counts\")\n",
    "axes[1].set_title(\"Total Counts Per Cell\")\n",
    "\n",
    "# Rank-ordered plot of total counts per cell - Figure 2C in the paper\n",
    "sorted_counts = np.sort(total_counts_per_cell)[::-1]\n",
    "\n",
    "axes[2].plot(sorted_counts)\n",
    "axes[2].set_yscale(\"log\")\n",
    "axes[2].set_xlabel(\"Ranked Cell Index\")\n",
    "axes[2].set_ylabel(\"Total Counts (log scale)\")\n",
    "axes[2].set_title(\"Rank-ordered Total Counts per Cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> most cells have comparable total cells\n",
    "\n",
    "--> the first ~20 cells have a lot more counts than the rest\n",
    "\n",
    "--> the last ~100 cells have very few counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of expressed genes per cell\n",
    "expressed_genes_per_cell = (exonCounts > 0).sum(axis=1)\n",
    "\n",
    "# plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "axes[0].scatter(range(len(expressed_genes_per_cell)), expressed_genes_per_cell)\n",
    "axes[0].set_xlabel(\"Cell Index\")\n",
    "axes[0].set_ylabel(\"Expressed Genes\")\n",
    "axes[0].set_title(\"Total Number of Expressed Genes per Cell\")\n",
    "\n",
    "axes[1].hist(expressed_genes_per_cell, bins=50)\n",
    "axes[1].set_xlabel(\"Total number of expressed genes per cell\")\n",
    "axes[1].set_ylabel(\"Number of cells\")\n",
    "axes[1].set_title(\"Distribution of Expressed Genes Per Cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fraction of mitochondrial genes\n",
    "\n",
    "# mt_like_genes = [g for g in genes if \"mt\" in g.lower()]\n",
    "# print(mt_like_genes)\n",
    "# after checking the gene names, we can assume that mitochondrial genes start with \"mt-\" or \"MT-\"\n",
    "mt_gene_mask = np.char.startswith(genes.astype(str).astype(\"U\"), \"mt-\")\n",
    "\n",
    "print(\"Number of mitochondrial genes found:\", np.sum(mt_gene_mask))\n",
    "\n",
    "# Sum counts over mitochondrial genes per cell\n",
    "mt_counts_per_cell = exonCounts[:, mt_gene_mask].sum(axis=1)\n",
    "\n",
    "# Fraction mitochondrial\n",
    "fraction_mito = mt_counts_per_cell / total_counts_per_cell\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.hist(fraction_mito, bins=50, color=\"salmon\", edgecolor=\"black\")\n",
    "plt.xlabel(\"Fraction of Mitochondrial Counts per Cell\")\n",
    "plt.ylabel(\"Number of Cells\")\n",
    "plt.title(\"Distribution of Mitochondrial RNA Content\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for any gene names containing 'mt' or 'MT'\n",
    "mt_like_genes = [g for g in genes if \"mt\" in g.lower()]\n",
    "print(mt_like_genes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2 QC Statistics per gene.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Frage - braucht es diesen plot? der mit log scale ist doch viel viel aussagekräftiger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean expression across all cells\n",
    "mean_expression_across_cells = exonCounts.mean(axis=0)\n",
    "print(\"Mean expression across all cells:\", mean_expression_across_cells.shape)\n",
    "# variance across all cells\n",
    "variance_expression_across_cells = exonCounts.var(axis=0)\n",
    "print(\"Variance across all cells:\", variance_expression_across_cells.shape)\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "ax.scatter(\n",
    "    mean_expression_across_cells,\n",
    "    variance_expression_across_cells,\n",
    "    s=5,\n",
    "    alpha=0.5,\n",
    ")\n",
    "ax.set_xlabel(\"Mean Expression Across Cells\")\n",
    "ax.set_ylabel(\"Variance Across Cells\")\n",
    "ax.set_title(\"Mean vs Variance of Gene Expression Across Cells\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot looks sparse, so log transform the data\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.scatter(\n",
    "    mean_expression_across_cells + 1,  # avoid log(0)\n",
    "    variance_expression_across_cells + 1,\n",
    "    s=5,\n",
    "    alpha=0.5,\n",
    ")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xlabel(\"Mean Expression Across Cells (log scale)\")\n",
    "ax.set_ylabel(\"Variance Across Cells (log scale)\")\n",
    "ax.set_title(\"Mean vs Variance of Gene Expression (log scale)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropout rate / fraction of cells where a gene has zero counts\n",
    "\n",
    "dropout_rate_per_gene = (exonCounts == 0).sum(axis=0) / exonCounts.shape[0]\n",
    "\n",
    "# Quick summary\n",
    "print(\"Mean dropout rate across all genes:\", np.mean(dropout_rate_per_gene))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.hist(dropout_rate_per_gene, bins=50, color=\"green\", edgecolor=\"black\")\n",
    "plt.xlabel(\"Dropout Rate (Fraction of Cells with Zero Counts)\")\n",
    "plt.ylabel(\"Number of Genes\")\n",
    "plt.title(\"Dropout Rate per Gene\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "count distributions of single genes within cell types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(rna_type))\n",
    "print(\"L2/3 IT_2\" in rna_type)  # hö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Group gene counts by cell type\n",
    "gene_names = rna_type\n",
    "unique_cell_types = np.unique(gene_names)\n",
    "gene_name = \"L2/3 IT_2\"\n",
    "gene_index = gene_names.get_loc(gene_name)\n",
    "gene_counts = exonCounts[:, gene_index]\n",
    "data = []\n",
    "\n",
    "for ct in unique_cell_types:\n",
    "    counts_in_group = gene_counts[np.array(cell_types) == ct]\n",
    "    data.append(counts_in_group)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.boxplot(data, labels=unique_cell_types)\n",
    "plt.ylabel(\"Counts of Sst\")\n",
    "plt.xlabel(\"Cell type\")\n",
    "plt.title(\"Expression of Sst across cell types\")\n",
    "plt.xticks(rotation=45)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2 Statistics for electrophysiological features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features overview\n",
    "ephysNames_filtered = ephysNames[\n",
    "    ~np.isin(ephysNames, features_exclude)\n",
    "]  # see above\n",
    "\n",
    "print(\n",
    "    \"Remaining electrophysiological features (n = {})\".format(\n",
    "        len(ephysNames_filtered)\n",
    "    )\n",
    ")\n",
    "for i, name in enumerate(ephysNames_filtered, 1):\n",
    "    print(f\"{i:2d}. {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descriptive statistics of ephysiological features (keep in mind that data is standardized)\n",
    "\n",
    "# print(\n",
    "#    \"Number of cells with ephys data: \",\n",
    "#    np.sum(np.isin(cells, ephysCells)),\n",
    "# )\n",
    "\n",
    "# dictionary to collect stats\n",
    "stats_dict = {\n",
    "    \"Mean\": [],\n",
    "    \"Std\": [],\n",
    "    \"Min\": [],\n",
    "    \"Max\": [],\n",
    "    \"Median\": [],\n",
    "    \"Skewness\": [],\n",
    "}\n",
    "\n",
    "# Compute stats per feature\n",
    "for i in range(X.shape[1]):\n",
    "    data = X[:, i]\n",
    "    stats_dict[\"Mean\"].append(np.mean(data))\n",
    "    stats_dict[\"Std\"].append(np.std(data))\n",
    "    stats_dict[\"Min\"].append(np.min(data))\n",
    "    stats_dict[\"Max\"].append(np.max(data))\n",
    "    stats_dict[\"Median\"].append(np.median(data))\n",
    "    stats_dict[\"Skewness\"].append(stats.skew(data))\n",
    "\n",
    "# Convert to DataFrame\n",
    "feature_stats_df = pd.DataFrame(stats_dict, index=ephysNames_filtered)\n",
    "\n",
    "print(\"Basic statistics of electrophysiological features (standardized):\")\n",
    "display(feature_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution of each electrophysiological feature\n",
    "# for i, feature in enumerate(ephysNames_filtered):\n",
    "#    plt.figure(figsize=(8, 4))\n",
    "#    sns.histplot(X[:, i], bins=30, kde=True, color=\"skyblue\")\n",
    "#    plt.title(f\"Distribution of {feature}\")\n",
    "#    plt.xlabel(feature)\n",
    "#    plt.ylabel(\"Density\")\n",
    "#    plt.grid()\n",
    "#    plt.show()\n",
    "\n",
    "n_features = len(ephysNames_filtered)\n",
    "n_cols = 4  # Number of columns in the grid\n",
    "n_rows = int(\n",
    "    np.ceil(n_features / n_cols)\n",
    ")  # Number of rows in the grid, rounded up\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 4, n_rows * 3))\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feature in enumerate(ephysNames_filtered):\n",
    "    ax = axes[i]\n",
    "    sns.histplot(\n",
    "        X[:, i],\n",
    "        bins=30,\n",
    "        kde=True,\n",
    "        color=\"skyblue\",\n",
    "        stat=\"density\",\n",
    "        ax=ax,\n",
    "    )\n",
    "    sns.kdeplot(\n",
    "        X[:, i], color=\"darkblue\", linewidth=1, ax=ax\n",
    "    )  # smoothed density plot (darkblue line)\n",
    "\n",
    "    ax.axvline(0, color=\"red\", linestyle=\"--\", linewidth=1)\n",
    "    ax.set_title(feature, fontsize=9, fontweight=\"bold\")\n",
    "    ax.set_xlabel(\"Standardized value\")\n",
    "    ax.set_ylabel(\"Density\")\n",
    "\n",
    "# Remove empty subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame with standardized ephys data\n",
    "ephys_df = pd.DataFrame(X, columns=ephysNames_filtered)\n",
    "\n",
    "# Compute Pearson correlation matrix\n",
    "corr_matrix = ephys_df.corr()\n",
    "\n",
    "# Test\n",
    "print(\"Correlation matrix shape:\", corr_matrix.shape)\n",
    "# print(corr_matrix.head())\n",
    "\n",
    "# \"high correlation\" threshold\n",
    "threshold = 0.6  # whats the best value?\n",
    "high_corr_pairs = []\n",
    "\n",
    "# Iterate over the upper triangle of the correlation matrix (excluding the diagonal) because the matrix is symmetric\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i + 1, len(corr_matrix.columns)):\n",
    "        corr_value = corr_matrix.iloc[i, j]\n",
    "        if abs(corr_value) > threshold:\n",
    "            feature_i = corr_matrix.columns[i]\n",
    "            feature_j = corr_matrix.columns[j]\n",
    "            high_corr_pairs.append((feature_i, feature_j, corr_value))\n",
    "\n",
    "# Print results\n",
    "print(\n",
    "    \"Feature pairings with high correlations (|corr| > {:.2f}):\".format(\n",
    "        threshold\n",
    "    )\n",
    ")\n",
    "for feature1, feature2, corr in sorted(\n",
    "    high_corr_pairs, key=lambda x: -abs(x[2])\n",
    "):\n",
    "    print(f\"{feature1:30s} x {feature2:30s}: {corr:+.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the correlation matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(\n",
    "    # sns.clustermap(  # clustermap clusters features based on correlation, kann einkommentiert werden\n",
    "    corr_matrix,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cmap=\"vlag\",\n",
    "    center=0,\n",
    "    square=True,\n",
    "    linewidths=0.5,\n",
    "    cbar_kws={\"shrink\": 0.8},\n",
    ")\n",
    "plt.title(\"Pairwise Pearson Correlation of Electrophysiological Features\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1 normalization + transformation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# exonCounts.shape = (n_cells, n_genes)\n",
    "# gene_names = list of gene names\n",
    "# cell_names = list of cell names\n",
    "\n",
    "# Compute total counts per cell\n",
    "total_counts_per_cell = exonCounts.sum(axis=1)\n",
    "\n",
    "# Avoid dividing by zero\n",
    "total_counts_per_cell[total_counts_per_cell == 0] = 1\n",
    "\n",
    "# Calculate CPM\n",
    "cpm = (exonCounts.T / total_counts_per_cell).T * 1e6\n",
    "\n",
    "# Log-transform\n",
    "log_cpm = np.log1p(cpm)\n",
    "\n",
    "# Create dataframe\n",
    "log_cpm_df = pd.DataFrame(log_cpm)  # , index=cell_names, columns=gene_names)\n",
    "\n",
    "# Save to CSV\n",
    "log_cpm_df.to_csv(\"log_cpm_normalized.csv\")\n",
    "\n",
    "print(\"Normalization complete. Log-CPM shape:\", log_cpm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2 select genes & apply PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
