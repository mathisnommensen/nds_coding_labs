{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Neural Data Science_\n",
    "\n",
    "Lecturer: Dr. Jan Lause, Prof. Dr. Philipp Berens\n",
    "\n",
    "Tutors: Jonas Beck, Fabio Seel, Julius Würzler\n",
    "\n",
    "Summer term 2025\n",
    "\n",
    "Student names: <span style='background: yellow'>*FILL IN YOUR NAMES HERE* </span>\n",
    "\n",
    "LLM Disclaimer: <span style='background: yellow'>*Did you use an LLM to solve this exercise? If yes, which one and where did you use it? [Copilot, Claude, ChatGPT, etc.]* </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Lab 4\n",
    "\n",
    "In this notebook you will work with preprocessed 2 photon calcium recordings, that have already been converted into spike counts for a population of cells from the Macaque V1. During the experiment the animal has been presented with several drifting grating stimuli, in response to which the neural activity was recorded. In this exercise sheet we will study how you can visualize the activity of multiple neural spike trains and assess whether a neuron is selective to a specific stimulus type.\n",
    "\n",
    "Download the data files ```nds_cl_4_*.csv``` from ILIAS and save it in the subfolder ```../data/```. We recommend you to use a subset of the data for testing and debugging, ideally focus on a single cell (e.g. cell number x). The spike times and stimulus conditions are read in as pandas data frames. You can solve the exercise by making heavy use of that, allowing for many quite compact computations. See [documentation](http://pandas.pydata.org/pandas-docs/stable/index.html) and several good [tutorials](https://www.datacamp.com/community/tutorials/pandas-tutorial-dataframe-python#gs.L37i87A) on how to do this. Of course, converting the data into classical numpy arrays is also valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "\n",
    "from scipy import signal as signal\n",
    "from typing import Tuple\n",
    "\n",
    "import itertools\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext jupyter_black\n",
    "\n",
    "%load_ext watermark\n",
    "%watermark --time --date --timezone --updated --python --iversions --watermark -p sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"../matplotlib_style.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes = pd.read_csv(\"../data/nds_cl_4_spiketimes.csv\")  # neuron id, spike time\n",
    "stims = pd.read_csv(\"../data/nds_cl_4_stimulus.csv\")  # stimulus onset in ms, direction\n",
    "\n",
    "stimDur = 2000.0  # in ms\n",
    "nTrials = 11  # number of trials per condition\n",
    "nDirs = 16  # number of conditions\n",
    "deltaDir = 22.5  # difference between conditions\n",
    "\n",
    "stims[\"StimOffset\"] = stims[\"StimOnset\"] + stimDur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We require some more information about the spikes for the plots and analyses we intend to make later. With a solution based on dataframes, it is natural to compute this information here and add it as additional columns to the `spikes` dataframe by combining it with the `stims` dataframe. We later need to know which condition (`Dir`) and trial (`Trial`) a spike was recorded in, the relative spike times compared to stimulus onset of the stimulus it was recorded in (`relTime`) and whether a spike was during the stimulation period (`stimPeriod`). But there are many options how to solve this exercise and you are free to choose any of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you may add computations as specified above\n",
    "spikes[\"Dir\"] = np.nan\n",
    "spikes[\"relTime\"] = np.nan\n",
    "spikes[\"Trial\"] = np.nan\n",
    "spikes[\"stimPeriod\"] = np.nan\n",
    "\n",
    "dirs = np.unique(stims[\"Dir\"])\n",
    "trialcounter = np.zeros_like(dirs)\n",
    "\n",
    "for i, row in stims.iterrows():\n",
    "    trialcounter[dirs == row[\"Dir\"]] += 1\n",
    "\n",
    "    i0 = spikes[\"SpikeTimes\"] > row[\"StimOnset\"]\n",
    "    i1 = spikes[\"SpikeTimes\"] < row[\"StimOffset\"]\n",
    "\n",
    "    select = i0.values & i1.values\n",
    "\n",
    "    spikes.loc[select, \"Dir\"] = row[\"Dir\"]\n",
    "    spikes.loc[select, \"Trial\"] = trialcounter[dirs == row[\"Dir\"]][0]\n",
    "    spikes.loc[select, \"relTime\"] = spikes.loc[select, \"SpikeTimes\"] - row[\"StimOnset\"]\n",
    "    spikes.loc[select, \"stimPeriod\"] = True\n",
    "\n",
    "spikes = spikes.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Plot spike rasters\n",
    "\n",
    "In a raster plot, each spike is shown by a small tick at the time it occurs relative to stimulus onset. Implement a function `plotRaster()` that plots the spikes of one cell as one trial per row, sorted by conditions (similar to what you saw in the lecture). Why are there no spikes in some conditions and many in others?\n",
    "\n",
    "If you opt for a solution without a dataframe, you need to change the interface of the function.\n",
    "\n",
    "*Grading: 3 pts*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotRaster(spikes: pd.DataFrame, neuron: int):\n",
    "    \"\"\"plot spike rasters for a single neuron sorted by condition\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    spikes: pd.DataFrame\n",
    "        Pandas DataFrame with columns\n",
    "            Neuron | SpikeTimes | Dir | relTime | Trial | stimPeriod\n",
    "\n",
    "    neuron: int\n",
    "        Neuron ID\n",
    "\n",
    "\n",
    "    Note\n",
    "    ----\n",
    "\n",
    "    this function does not return anything, it just creates a plot!\n",
    "    \"\"\"\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # Write a raster plot function for the data (2 pts)\n",
    "    # -------------------------------------------------\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find examples of \n",
    "1. a direction selective neuron\n",
    "2. an orientation selective neuron \n",
    "3. neither\n",
    "\n",
    "and explain your choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "# Find and explain examples? (1 pt)\n",
    "# ---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Plot spike density functions\n",
    "\n",
    "Compute an estimate of the spike rate against time relative to stimulus onset. There are two ways:\n",
    "* Discretize time: Decide on a bin size, count the spikes in each bin and average across trials. \n",
    "* Directly estimate the probability of spiking using a density estimator with specified kernel width. \n",
    "\n",
    "For full points, the optimal kernel- or bin-width needs to be computed.\n",
    "\n",
    "Implement one of them in the function `plotPSTH()`. If you dont use a dataframe you may need to change the interface of the function.\n",
    "\n",
    "\n",
    "*Grading: 4 pts*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotPSTH(spikes: pd.DataFrame, neuron: int):\n",
    "    \"\"\"Plot PSTH for a single neuron sorted by condition\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    spikes: pd.DataFrame\n",
    "        Pandas DataFrame with columns\n",
    "            Neuron | SpikeTimes | Dir | relTime | Trial | stimPeriod\n",
    "\n",
    "    neuron: int\n",
    "        Neuron ID\n",
    "\n",
    "\n",
    "    Note\n",
    "    ----\n",
    "\n",
    "    this function does not return anything, it just creates a plot!\n",
    "    \"\"\"\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # Implement one of the spike rate estimates (3 pts)\n",
    "    # -------------------------------------------------\n",
    "\n",
    "    for row, dir in enumerate(dirs):\n",
    "        # ---------------------------------------------\n",
    "        # Plot the obtained spike rate estimates (1 pt)\n",
    "        # ---------------------------------------------\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the same 3 examples you selected in Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Fit and plot tuning functions\n",
    "\n",
    "The goal is to visualize the activity of each neuron as a function of stimulus direction. First, compute the spike counts of each neuron for each direction of motion and trial.  The result should be a matrix `x`, where $x_{jk}$ represents the spike count of the $j$-th response to the $k$-th direction of motion (i.e. each column contains the spike counts for all trials with one direction of motion).\tIf you used dataframes above, the `groupby()` function allows to implement this very compactly. Make sure you don't loose trials with zero spikes though. Again, other implementations are completely fine.\n",
    "\n",
    "Fit the tuning curve, i.e. the average spike count per direction, using a von Mises model. To capture the non-linearity and direction selectivity of the neurons, we will fit a modified von Mises function:\n",
    "\n",
    "$$ f(\\theta) = \\exp(\\alpha + \\kappa (\\cos (2*(\\theta-\\phi))-1) + \\nu (\\cos (\\theta-\\phi)-1))$$\n",
    "\n",
    "Here, $\\theta$ is the stimulus direction. Implement the von Mises function in `vonMises()` and plot it to understand how to interpret its parameters $\\phi$, $\\kappa$, $\\nu$, $\\alpha$. Perform a non-linear least squares fit using a package/function of your choice. Implement the fitting in `tuningCurve()`. \n",
    "\n",
    "Plot the average number of spikes per direction, the spike counts from individual trials as well as your optimal fit.\n",
    "\n",
    "Select two cells that show nice tuning to test your code.\n",
    "\n",
    "*Grading: 5 pts*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vonMises(θ: np.ndarray, α: float, κ: float, ν: float, ϕ: float) -> np.ndarray:\n",
    "    \"\"\"Evaluate the parametric von Mises tuning curve with parameters p at locations theta.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    θ: np.array, shape=(N, )\n",
    "        Locations. The input unit is degree.\n",
    "\n",
    "    α, κ, ν, ϕ : float\n",
    "        Function parameters\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    f: np.array, shape=(N, )\n",
    "        Tuning curve.\n",
    "    \"\"\"\n",
    "\n",
    "    # -----------------------------------\n",
    "    # Implement the Mises model (0.5 pts)\n",
    "    # -----------------------------------\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the von Mises function while varying the parameters systematically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# plot von Mises curves with varying parameters and explain what they do (2 pts)\n",
    "# ------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuningCurve(counts: np.ndarray, dirs: np.ndarray, show: bool = True) -> np.ndarray:\n",
    "    \"\"\"Fit a von Mises tuning curve to the spike counts in count with direction dir using a least-squares fit.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    counts: np.array, shape=(total_n_trials, )\n",
    "        the spike count during the stimulation period\n",
    "\n",
    "    dirs: np.array, shape=(total_n_trials, )\n",
    "        the stimulus direction in degrees\n",
    "\n",
    "    show: bool, default=True\n",
    "        Plot or not.\n",
    "\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    p: np.array or list, (4,)\n",
    "        parameter vector of tuning curve function\n",
    "    \"\"\"\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # Compute the spike count matrix (0.5 pts)\n",
    "    # ----------------------------------------\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # fit the von Mises tuning curve to the spike counts (0.5 pts)\n",
    "    # ------------------------------------------------------------\n",
    "\n",
    "\n",
    "    if show:\n",
    "        # --------------------------------------------\n",
    "        # plot the data and fitted tuning curve (1 pt)\n",
    "        # --------------------------------------------\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot tuning curve and fit for different neurons. Good candidates to check are 28, 29 or 37. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(spikes, neuron):\n",
    "    spk_by_dir = (\n",
    "        spikes[spikes[\"Neuron\"] == neuron]\n",
    "        .groupby([\"Dir\", \"Trial\"])[\"stimPeriod\"]\n",
    "        .sum()\n",
    "        .astype(int)\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    dirs = spk_by_dir[\"Dir\"].values\n",
    "    counts = spk_by_dir[\"stimPeriod\"].values\n",
    "\n",
    "    # because we count spikes only when they are present, some zero entries in the count vector are missing\n",
    "    for i, Dir in enumerate(np.unique(spikes[\"Dir\"])):\n",
    "        m = nTrials - np.sum(dirs == Dir)\n",
    "        if m > 0:\n",
    "            dirs = np.concatenate((dirs, np.ones(m) * Dir))\n",
    "            counts = np.concatenate((counts, np.zeros(m)))\n",
    "\n",
    "    idx = np.argsort(dirs)\n",
    "    dirs_sorted = dirs[idx]  # sorted dirs\n",
    "    counts_sorted = counts[idx]\n",
    "\n",
    "    return dirs_sorted, counts_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------\n",
    "# plot the average number of spikes per direction, the spike \n",
    "# counts from individual trials as well as your optimal fit \n",
    "# for different neurons (0.5 pts)\n",
    "# ----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Permutation test for direction tuning\n",
    "\n",
    "Implement a permutation test to quantitatively assess whether a neuron is direction/orientation selective. To do so, project the vector of average spike counts, $m_k=\\frac{1}{N}\\sum_j x_{jk}$ on a complex exponential with two cycles, $v_k = \\exp(\\psi i \\theta_k)$, where $\\theta_k$ is the $k$-th direction of motion in radians and $\\psi \\in 1,2$ is the fourier component to test (1: direction, 2: orientation). Denote the projection by $q=m^Tv$. The magnitude $|q|$ tells you how much power there is in the $\\psi$-th fourier component. \n",
    "\n",
    "Estimate the distribution of |q| under the null hypothesis that the neuron fires randomly across directions by running 1000 iterations where you repeat the same calculation as above but on a random permutation of the trials (that is, randomly shuffle the entries in the spike count matrix x). The fraction of iterations for which you obtain a value more extreme than what you observed in the data is your p-value. Implement this procedure in the function ```testTuning()```. \n",
    "\n",
    "Illustrate the test procedure for one of the cells from above. Plot the sampling distribution of |q| and indicate the value observed in the real data in your plot. \n",
    "\n",
    "How many cells are tuned at p < 0.01?\n",
    "\n",
    "*Grading: 3 pts*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testTuning(\n",
    "    counts: np.ndarray,\n",
    "    dirs: np.ndarray,\n",
    "    psi: int = 1,\n",
    "    niters: int = 1000,\n",
    "    show: bool = False,\n",
    "    random_seed: int = 2046,\n",
    ") -> Tuple[float, float, np.ndarray]:\n",
    "    \"\"\"Plot the data if show is True, otherwise just return the fit.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    counts: np.array, shape=(total_n_trials, )\n",
    "        the spike count during the stimulation period\n",
    "\n",
    "    dirs: np.array, shape=(total_n_trials, )\n",
    "        the stimulus direction in degrees\n",
    "\n",
    "    psi: int\n",
    "        fourier component to test (1 = direction, 2 = orientation)\n",
    "\n",
    "    niters: int\n",
    "        Number of iterations / permutation\n",
    "\n",
    "    show: bool\n",
    "        Plot or not.\n",
    "\n",
    "    random_seed: int\n",
    "        Random seed for reproducibility.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    p: float\n",
    "        p-value\n",
    "    q: float\n",
    "        magnitude of second Fourier component\n",
    "\n",
    "    qdistr: np.array\n",
    "        sampling distribution of |q| under the null hypothesis\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # -------------------------------\n",
    "    # calculate m, nu and q (0.5 pts)\n",
    "    # -------------------------------\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Estimate the distribution of q under the H0 and obtain the p value (1 pt)\n",
    "    # -------------------------------------------------------------------------\n",
    "    # ensure reproducibility using a random number generator\n",
    "    # hint: access random functions of this generator\n",
    "    rng = np.random.default_rng(random_seed)\n",
    "\n",
    "\n",
    "    if show:\n",
    "        # add plotting code here\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show null distribution for the example cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Plot null distributions for example cells 28 & 29. (1 pt)\n",
    "# ---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test all cells for orientation and direction tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------\n",
    "# Test all cells for orientation / direction tuning. \n",
    "# Which ones are selective? (0.5 pts)\n",
    "# --------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of direction tuned neurons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of orientation tuned neurons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
